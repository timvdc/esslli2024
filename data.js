evening_lecturers = [
  {
    "lecturer": "Marko Robnik Šikonja",
    "title": "Large language models for cross-lingual transfer",
    "group": "Evening",
    "description": "Currently, the most successful approach to natural language processing is based on large pretrained language models using the transformer architecture of neural networks. These are typically pretrained on huge text corpora on the tasks of predicting next tokens or masked tokens. While most existing models are predominantly monolingual, multilingual variants also exist and can help in cross-lingual transfer of knowledge and models. We will present a few types of large language models, focusing on cross-lingual transfer. We will show their strengths and weaknesses in text classification, summarization, and question answering.",
    "id": "evening1",
    "date": "2023-08-01",
    "time": "19:00-20:30",
    "room": "PA",
    "moderator": "Slavko Žitnik",
    "website": "https://fri.uni-lj.si/en/about-faculty/employees/marko-robnik-sikonja"
  },{
    "lecturer": "Malvina Nissim",
    "title": "Language Technology <preposition> Society",
    "group": "Evening",
    "description": "The recognition of society’s role in language technology has become essential and cannot be overlooked. Still, plenty of research in Natural Language Processing does not explicitly account for such interplay. This evening lecture will zoom in on precisely this aspect. “Precisely” is an ambitious term, since the very definition of the relationship between language technology and society is subject to multiple interpretations, both in the context of scientific research as well as in connection with the general public, who currently is very much exposed to, interested in, and involved with language-based artificial intelligence tools. Through recent work I’ve carried out with my group, and through personal reflections, I will unpack this exciting relationship from different angles.",
    "id": "evening2",
    "date": "2023-08-03",
    "time": "19:00-21:00",
    "room": "PA",
    "moderator": "Valerio Basile",
    "website": "https://malvinanissim.github.io/"
  },{
    "lecturer": "Beniamino Accattoli",
    "title": "The Cost of the lambda Calculus and the Semantics of Sharing",
    "group": "Evening",
    "description": "The lambda calculus is an expressive mathematical formalism that elegantly captures the core of functional programming languages, while providing at the same time compact representations of intuitionistic logic proofs.\nThe first part of the talk shall survey the recent advances in the study of reasonable cost models for the lambda calculus, that is, of time and space cost measures that are equivalent to those of Turing machines. In particular, it shall overview how understanding the role of sharing in the evaluation process is crucial for both time and space, but for opposite reasons.\nThe second part of the talk shall show that extending the lambda calculus with first-class sharing is not a minor extension, as crucial semantic properties and results break, and new tools and richer theories need to be developed.",
    "id": "evening3",
    "date": "2023-08-08",
    "time": "19:00-20:30",
    "room": "PA",
    "moderator": "Valentin Goranko",
    "website": "https://sites.google.com/site/beniaminoaccattoli/"
  },{
    "lecturer": "Darja Fišer",
    "title": "The Good, the Bad and the Ugly of Language Technology Infrastructure",
    "group": "Evening",
    "description": "Advances in digitization and datafication have been transformative for linguistics and other disciplines that work with language materials. This has increased the need for research infrastructures that supports the development, documentation, archiving, dissemination, reuse and citation of language resources and tools which is prerequisite for verifiable, reproducible and ethical research. Still, the potential of research infrastructures in language technology remains undervalued and underutilised in the real world of language-based research and education. Based on the work conducted within my research group as well as through personal observations, I will address the good, the bad and the ugly aspects of adopting the research infrastructure principles that is built around the Open Science and FAIR data paradigm.",
    "id": "evening4",
    "date": "2023-08-10",
    "time": "19:00-21:00",
    "room": "PA",
    "moderator": "John McCrae",
    "website": "https://www.inz.si/en/Scientific-research-department/Darja-Fiser_en/"
  }
]

week1 = [
  {
    "time": "9.00am - 10.30am",
    "groups": [
      [
        {
          "lecturer": "Howard Gregory",
          "title": "Language and Logics",
          "group": "Foundational",
            "description": "This course introduces the use of formal logic in natural language semantics. It has no prerequisites, but an introductory linguistics course is desirable. The coverage will be limited to classical first order logic (FOL). This is far from the only logic used in linguistics, but it is presupposed by most advanced work. FOL is presented in a way which highlights the assumptions and choices made and the plurality of logics (as promised by the title), providing pointers to further directions of study.",
            "id": "12"
        },
        {
          "lecturer": "Matthew Mandelkern and Melissa Fusco",
          "title": "Conditionals, probability, and decision",
          "group": "Introductory",
          "description": "This advanced course in Language and Logic will explore interactions between the theory of the conditional and the theory of rational decision. Stalnaker (1971) and many following have argued that there is a close connection between conditionals and rational decision: at a first pass, you should do the act that, in expectation, WOULD bring about the best consequences IF you were to do it. This intuitive picture both constrains, and is constrained by, the theory of the conditional (in particular, its logic and semantics, and corresponding probabilities). The course will explore the interacting perspectives of decision theory (Fusco’s specialty) and conditional semantics (Mandelkern’s specialty).",
          "id": "19"
        }
      ],
      [
        {
          "lecturer": "John McCrae",
          "title": "Introduction to Linguistic Data Science ",
          "group": "Foundational",
          "description": "Big data is fundamentally changing the way that linguists can investigate linguistic facts leading to a new research area which combines data science with linguistics. This course provides an introduction to the new area of linguistic data science by means of an introductory course with hands-on data analysis that is focused on key questions in linguistics. This course will first provide a basic introduction to data science and in particular how this can be applied to large corpora using natural language processing techniques. We will then show how this can be used to find answers to problems in syntax, semantics, multilinguality and other areas of linguistics, along with a summary giving perspectives on how these methods can be applied to students’ own research.",
          "id": "4",
        },
        {
          "lecturer": "Damir Cavar and Billy Dickson",
          "title": "Generative AI and Symbolic Knowledge Representations: Large Language Models, Knowledge, and Reasoning",
          "group": "Introductory",
          "description": "This course is intended to be an Advanced Course addressing Large Language Models, or in general Large Models (multi-modal) and Knowledge Representations for reasoning and semantic processing. We discuss: - What are knowledge representations? This is about Ontologies, Knowledge Graphs, and semantic web approaches to handle for example Description Logic representations and reasoning. - What are Large Language Models and, ultimately, Large Models? This is mainly addressing so-called Generative AI, approaches to building and training models, and their application and limits, when the input is unstructured text or visual information only. - How can LMs and computational semantics approaches be combined? This addresses general problems of LMs (e.g., hallucinations), and we discuss how symbolic (and also probabilistic) knowledge representations can be linked to LMs generating more reliable responses, summaries, even pragmatic aspects like implicatures and presuppositions. We also discuss how LMs can be trained on knowledge and semantic representations to improve their reasoning capabilities. This course can be accompanied by extensive material, code, and instructions shared with students and the community, including hands-on access to the respective technologies. Depending on the audience, interest, and goals, we can adjust the level and content and design the course to include a discussion of state-of-the-art approaches to the generation of Ontologies, taxonomies, and Knowledge Graph representations. This course might sound technologically challenging, but we can assure you that it is actually within the scope of advanced undergraduate students, certainly appropriate for interested graduate students coming with basic computation experience, knowledge of statistics, and interest in logic, semantics, and knowledge representations.",
          "id": "25",
        }
      ],
      [
        {
          "lecturer": "Dan Frumin and Jorge A. Pérez",
          "title": "Propositions as Sessions: Logical Foundations of Concurrent Computation",
          "group": "Foundational",
          "description": "The Curry-Howard(-deBruijn) correspondence, also known under the slogan of \“Propositions as Types\”, is arguably the most important bridge between logic and computation. The connection between intuitionistic logic and lambda-calculus is the most familiar instance of this bridge. The correspondence can be seen as a fruitful principle for logically-informed foundations of programming languages. This introductory course will explore recent work on the Curry-Howard correspondence between substructural logics and concurrent processes, dubbed as \“Propositions as Sessions\”. Following a gradual approach, participants will learn how Girard’s linear logic and its extensions serve as a basis for structuring message-passing concurrent programs through the discipline of session types. No specific prerequisites are assumed for this course, except for familiarity with formal logic; participants will get familiar with the selected topics in Substructural Logics, Concurrency Theory, and Programming Languages. The course will close with an overview of prospective research challenges.",
          "id": "50"
        },
        {
          "lecturer": "Balder ten Cate and Frank Wolter",
          "title": "A Modern Introduction to Craig Interpolation",
          "group": "Introductory",
          "description": "Craig interpolants are, intuitively, logical formulas that ``explain'' why an entailment between formulas P and Q holds by reference to the shared vocabulary of P and Q. They nowadays play a fundamental role not only in mathematical and philosophical logic, but also in applied areas ranging from automated deduction to program verification, databases and knowledge representation. They are used, for instance, as explainers of why sets of program states are disjoint and as synthesisers of concepts, programs and queries. The purpose of this course is to introduce the logical foundations and applications of Craig interpolation. We cover formalisms ranging from propositional and first-order logic to description and temporal logic. We illustrate modern applications, focusing on databases and knowledge representation. Finally, we also discuss recent research on what to do if a logic does not enjoy the Craig interpolation property, i.e., when there are entailments without Craig interpolants. We give an an introduction to Craig Interpolation and its modern applications in computer science, including databases, knowledge representation, complexity theory, and program verification.",
          "id": "43"
        }
      ],
      []
    ]
  },
  {
    "time": "10.30am - 11.00am",
    "groups": [],
    "title": "coffee break"
  },
  {
    "time": "11.00am - 12.30pm",
    "groups": [
      [
        {
          "lecturer": "Dan Zeman",
          "title": "	The Semantics and Pragmatics of Slurs",
          "group": "Introductory",
          "description": "Whether we like it or not, “bad words” are ubiquitous in natural language. While using such words has sometimes no significant effects, in many cases their use can produce real harm, by denigrating, silencing, and marginalizing the people they target. Slurs are one such type of “bad words”. Most researchers agree that the main function of slurs is that of derogating or dehumanizing, of signalling that their targets are unworthy of equal standing or full respect as persons. Figuring out how slurs achieve their main function is an important topic in contemporary philosophy of language and linguistics. In this introductory course, my aim is to present the main characteristics of slurs and their uses (not limited to derogation), explore the main views on their semantics and pragmatics, and show how they are connected to larger social phenomena like power structures and communal identities.",
          "id": "62"
        },
        {
          "lecturer": "Cameron Domenico Kirk-Giannini and Henry Schiller",
          "title": "Speech Acts: Dynamic Force and Conversational Update",
          "group": "Introductory",
          "description": "Stalnaker’s theory of the dynamic effect of assertion treats assertoric updates as intersective functions from one context to another. For Stalnaker, this is the characteristic way in which assertion changes the state of a conversation: its dynamic force. This course will introduce students to work in formal pragmatics on the dynamic force of various speech acts. We’ll begin with an introduction to speech act theory and discourse context, and then introduce Stalnaker’s theory of assertion as well as some challenges to that theory. The next part of the course will consider formal theories of directives and questions. In this section, our aim will be to assess whether we can account for the dynamic effects of these speech acts while remaining within the Stalnakerian model — and if not, how else we might account for those effects. Finally, we’ll turn our attention to topics that push the boundaries of traditional theories of formal pragmatics, such as felicitous underspecification and peripheral content.",
          "id": "15"
        }
      ],
      [
        {
          "lecturer": "Mark Steedman",
          "title": "Categorial Foundations of Natural Language Structures",
          "group": "Introductory",
          "description": "The course analyses the problem of natural language structure, as characterized by language diversity, requirements of language acquisition by children, extreme ambiguity, and discontinuity (where elements that seem to belong together semantically are separated in the sentence), in terms of an extension of classical Categorial Grammar. The problem will be analyzed in its own right and from the ground up, without any specifically linguistic theoretical assumptions. However, along the way, links to various existing linguistic and computational theories of language will be established, as needed by the students.",
          "id": "55"
        },
        {
          "lecturer": "Andreas Liesenfeld and Mark Dingemanse",
          "title": "Introduction to Conversational AI",
          "group": "Foundational",
          "description": "Conversations come naturally to us. While we humans learn language through conversation, interactive language use is arguably the holy grail of speech and language processing. With large language modelling (LLM) approaches, progress was made towards building more interactive agents. Yet, modelling human-like conversational AI remains a moonshot. This foundational course delves into why modelling conversational competence is so challenging. It also takes stock of recent engineering breakthroughs in building conversational AI systems using instruction-tuned LLM models such as ChatGPT, Llama or Mistral. Students will learn the basics of interactive language modelling and explore the scientific and theoretical foundations of understanding structure and variation in conversational speech data in hands-on tutorials. We will work through recent empirical and computational work on speech corpora, speech recognition, and technology assessment. Aspects of conversational infrastructure covered include turn-taking, interactive repair, and action ascription. We conclude by touching upon societal and ethical issues that emerge alongside the rise of conversational AI. This course might appeal to anyone interested in recent approaches to conversational AI and understanding why talking machines still struggle to hold up their end of a conversation. Some experience working with Python and Jupyter notebook required.",
          "id": "9",
        }
      ],
      [
        {
          "lecturer": "Mikhail Rybakov and Dmitry Shkatov",
          "title": "Computational aspects of first-order modal logics",
          "group": "Advanced",
          "description": "The course will introduce students to computational aspects of first-order modal logics. The course will contain a brief, self-contained introduction to first-order modal logics and then will cover the most important techniques for proving decidability, undecidability, and lack of recursive enumerability for first-order modal logics and their fragments. The course is intended for a broad audience of graduate students interested in modal reasoning and its computational aspects. This includes students of logic, philosophy, computer science, linguistics, and mathematics. The course will assume a basic familiarity with the classical first-order logic and with Kripke semantics for propositional modal logics.",
          "id": "53",
        },
        {
          "lecturer": "Valentin Goranko",
          "title": "Games Logicians Play",
          "group": "Advanced",
          "description": "This course will introduce, discuss and illustrate with examples the most important games in logic, including: dialogue argumentation games, evaluation games, model building games, and model comparison games. These games can be used for model checking, constructive satisfiability testing, to characterize logical equivalences of models, and to prove non-definability results. Optionally, I will also introduce and discuss game-theoretic semantics with incomplete information for logical languages.",
          "website": "Course webpage can be found at https://www2.philosophy.su.se/goranko/Courses2024/ESSLLI2024_GamesLogiciansPlay.html",
          "id": "20"
        }
      ],
      [
        {
          "lecturer": "Carla Umbach and Yael Greenberg",
          "title": "Incremental constructions within and across languages: Where degrees, eventualities and discourse dynamics interact",
          "group": "Workshop",
          "website": "placeholder",
          "description": "Incrementality ('adding up to a larger whole', König 1991) can be expressed by English 'more' (1), German 'noch/mehr', Hebrew 'od', Mandarin 'hai' etc. (1) Some/3 kids sang at the party. Then some/3 more kids danced. While studies of individual incremental constructions (INCRs) exist, there are still many gaps in their understanding. This workshop aims to fill such gaps (A) by studying how INCRs syntactically and semantically vary, both across and within languages, and (B) by trying to integrate insights from two approaches to incrementality, which thus far have not interacted: Degree-based approaches (e.g. Greenberg 2010, Thomas 2011), taking INCRs to express additive measurements of eventualities, and discourse-based approaches (e.g. Eckardt 2007, Umbach 2012, Grubic 2018) taking INCRs to be focus/QUD-sensitive, managing the growth of information along discourse-salient dimensions (e.g. event/discourse time). The topic of this workshop is closely related to that of the Week 1 course on 'Scalarity and Additivity in Natural Language'. Course participants are welcome.",
          "id": "2",
        }
      ]
    ]
  },
  {
    "time": "12.30pm - 2.00pm",
    "groups": [],
    "title": "lunch"
  },
  {
    "time": "2.00pm - 3.30pm",
    "groups": [
      [
        {
          "lecturer": "Jun Chen and Swantje Toennis",
          "title": "Theoretical and empirical approaches to cleft constructions",
          "group": "Introductory",
          "description": "This course aims to cross-linguistically investigate cleft constructions from theory-driven and empirical perspectives. An English cleft construction is a sentence of the form It is ... who ..., as exemplified in (1). (1) It was Sally who danced. We will first introduce hypotheses for capturing the meanings of clefts, their use conditions and their functions in discourse. In addition, we will discuss formal analyses that attempt to derive the cleft’s exhaustive inference (e.g., nobody other than Sally danced in (1)), and analyses demonstrating interactions between clefts and Questions Under Discussion (Roberts, 2012). Up-to-date psycholinguistic studies and corpus research which cross-linguistically test these theoretical claims (e.g., in Chinese, German, etc.) will also be introduced alongside. We will examine various experimental designs, and investigate empirical results, which seem to clash with theoretical predictions. The goal of this course is not only to convey state-of-the-art knowledge on cleft constructions to the students, but also to inspire and explore new theoretical and empirical ideas together with the students.",
          "id": "22"
        },
        {
          "lecturer": "Nazarre Merchant and Alan Prince",
          "title": "Analyzing OT Typologies: Order, Equivalence and the Mother of all Tableaux",
          "group": "Advanced",
          "description": "An OT (Optimality Theory) typology is comprised of a set of grammars which themselves are sets of total orders. Every typology has an associated geometry which provides an inherent classification of the grammars that constitute it. In this course we will develop these notions, showing how constraints, which at the lowest level are numerical comparisons between linguistic candidates, can be abstractly viewed as providing comparisons between entire grammars. From this perspective, constraints provide both order and equivalence structures on the grammars, an “Equivalence-augmented Partial Order” (EPO), which determine all licit typological classifications of a given theory. The set of all such EPOs for a typology is termed the Mother of all Tableaux (MOAT). We will develop these notions in both the concrete and abstract, using basic syllable theory as an entrée into the abstract categories of OT typologies.",
          "id": "46"
        }
      ],
      [
        {
          "lecturer": "Haim Dubossarsky and Pierluigi Cassotti",
          "title": "Computational Models for Semantic Change and their Applications in Multidisciplinary Research",
          "group": "Introductory",
          "description": "",
          "id": "23",
          //"website": "https://sites.google.com/view/esslli2023course",
          //"course-material": [
          //  {"title": "Course website", "link": "https://sites.google.com/view/esslli2023course"}
          //]
        },
        {
        }
      ],
      [
        {
          "lecturer": "Philippe Balbiani and Cigdem Gencer",
          "title": "Intuitionistic Modal Logic",
          "group": "Foundational",
          "description": "Among those mixing together Boolean concepts and modal concepts, the search for minimality has prompted multifarious debates. Most of these debates have now faded. In fact, they have not survived the end of the syntactic era of modal logic. Before the advent, in the 1960s, of the concept of Kripke frames, it was unclear which modal logic is the most appropriate candidate for the title of ``minimal modal logic''. Today, although the modal logic K does not contain any of the formulas expressing the properties usually associated to the modal concepts of necessity and possibility, everyone accepts the fact that K is the minimal modal logic. Among those combining together intuitionistic concepts and modal concepts, the quest for minimality has caused numerous discussions. Some of these discussions are still alive. Indeed, two approaches are in direct opposition: the intuitionistic approach set out by Fischer Servi (1977, 1978, 1984) giving rise to the intuitionistic modal logic IK and the constructive approach expounded by Wijesekera (1990) giving rise to the intuitionistic modal logics WK and CK. And there is no consensus of what should be the ``minimal intuitionistic modal logic''. The reason for being of the intuitionistic approach set out by Fischer Servi is mainly the fact that a minimal intuitionistic modal logic should contain the formulas whose standard translation in a first-order language are intuitionistically valid. Therefore, the supporters of this approach consider intuitionistic modal logic IK that contains the formulas ◊(pVq)->◊pV◊q and ¬<>false despite their non-constructive character. The justification of the constructive approach expounded by Wijesekera chiefly rests on the fact that the formulas of a minimal intuitionistic modal logic should have a constructive character. As a result, the upholders of this approach consider intuitionistic modal logic WK that does not contain the formula ◊(pVq)->◊pV◊q. The most radical of them also consider intuitionistic modal logic CK that does not contain either the formula ¬<>false. There is no sense in comparing the arguments for and against the intuitionistic approach giving rise to the intuitionistic modal logic IK and the constructive approach giving rise to the intuitionistic modal logics WK and CK. To convince the reader of this opinion, it suffices to mention how these approaches differently define the truth condition of diamond-formulas in their relational semantics, although they consider the same truth condition of box-formulas. This difference in the definition of the truth condition of diamond-formulas shows that the connective ◊ à la Fischer Servi and the connective ◊ à la Wijesekera are as separate as are, for example, the connectives of disjunction and conjunction in any intermediate logic. In this course, we firstly offer a self-contained overview of intermediate logics and modal logics. Secondly, we survey the different intuitionistic and constructive approaches to modal logic that have been proposed in the literature. We thirdly present the most important motivations for the introduction of such approaches: Curry-Howard correspondence between proofs and programs, Brouwer-Heyting-Kolmogorov interpretation of logic, type systems for staged computation, formalization of distributed computation, hardware verification, etc. Fourthly, we develop the proof theory, the relational semantics and the algebraic semantics of the different intuitionistic and constructive approaches to modal logic. We fifthly introduce an appropriate candidate for the title of minimal intuitionistic modal logic, an intuitionistic modal logic strictly contained in IK and comparable neither with WK, nor with CK. For some of its extensions, we study the axiomatization/completeness and the decidability/complexity of the set of their valid formulas. This course will mainly address logical and computational aspects of the combination of intuitionistic concepts and modal concepts.",
          "id": "11",
        },
        {
          "lecturer": "Xinghan Liu and Emiliano Lorini",
          "title": "Logics for Explaining AI Systems",
          "group": "Introductory",
          "description": "The notion of explanation plays a pivotal role in artificial intelligence and machine learning, in which there is an increasing demand of explaining the behavior of systems trained on data, especially deep learning systems. Different notions of of explanation have been proposed and studied in the area of eXplainable AI (XAI), varying according to different dimensions such as global versus local and model-agnostic versus model-specific. In this course we will introduce several modal logics for explaining the behaviors and predictions of AI systems, including classifier systems and causal models, of which artificial neural networks are special instances. These logics support reasoning about different types of explanations including abductive, contrastive, counterfactual and causal explanation. We will discuss the proof-theoretic, decidability and complexity aspects of these logics and illustrate their expressiveness with examples.",
          "id": "39",
        }
      ],
      [
        {
          "lecturer": "Justine Cassell and David Traum",
          "title": "Conversational Grounding in the Age of Large Language Models",
          "group": "Workshop",
          "website": "placeholder",
          "description": "Conversational Grounding is the process whereby participants in a conversation establish new common ground; that is, shared information that can subsequently be referred to. The conversational grounding process includes not just transmission of information via declarative utterances, but also visual, inferential, and interactive feedback processes. While there has been a substantial work on conversational grounding, many open problems remain, particularly when applied to different situations and activities, involving different numbers and types of participants, different perceptual and action affordances, and different goals. Moreover, new resources involving large language models change the nature of grounding processes and create new challenges even when they may improve the ability to solve some issues. The moment is therefore to bring together researchers working on aspects of Conversational Grounding for a workshop to increase common ground on the topic, and disseminate new best practices for computing, modeling and implementing conversational grounding in dialogue systems.",
          "id": "66",
        }
      ]
    ]
  },
  {
    "time": "3.30pm - 3.50pm",
    "groups": [],
    "title": "coffee break"
  },
  {
    "time": "3.50pm - 4.50pm",
    "groups": [],
    "title": "Student Session (StuS)<br/>Room: PA",
    "link": "courses-workshops-accepted/student-session-call.html"
  },
  {
    "time": "5.00pm - 6.30pm",
    "groups": [
      [
        {
          "lecturer": "Linmin Zhang",
          "title": "Scalarity and additivity in natural language",
          "group": "Advanced",
          "description": "This course addresses the connection between scalarity and additivity in natural language. Scalarity has mainly been investigated within degree semantics, which aims to study how natural language expresses measurement and comparison along an abstract dimension, i.e., a scale composed of a totally ordered set of scalar values (degrees or intervals). Additivity is mainly about expressions that bring an existential presupposition in a domain of entities: e.g., additive particles like \"another\" presuppose the existence of a similar item. Recent research suggests a connection between scalarity and additivity (e.g., Greenberg 2010, Thomas 2010, Zhang and Ling 2021): comparison means additivity along a scale. This course addresses the conceptual, empirical, and technical aspects of this connection across domains. The course will start with an additivity-based perspective on comparatives, introducing the conceptual benefits and technical details of connecting research on scalarity and additivity. Then we will discuss various research questions within this perspective.",
          "id": "17"
        },
        {
        }
      ],
      [
        {
          "lecturer": "Jonathan Rawski and David Chiang",
          "title": "Expressivity of Transformers: Logic, Circuits, and Formal Languages",
          "group": "Introductory",
          "description": "A major advancement in language modeling is the use of the transformer architecture. But, what problems can transformers solve, what problems can they not solve, and how can we prove it? This course examines the expressivity of transformers through the lens of computability and complexity theory. We will situate transformers within the landscape of automata, boolean circuits, and formal logics. We will discuss what is currently known about transformers' capabilities and limitations, address the practical implications of these results for natural language processing, and identify some directions for future work. Participants will gain a comprehensive understanding of transformers' expressive power in terms of the problems they fundamentally can and cannot solve.",
          "id": "37",
        },
        {
        }
      ],
      [
        {
          "lecturer": "Alexandru Baltag and Sonja Smets",
          "title": "Dynamic Logics for Communication and Data Exchange",
          "group": "Foundational",
          "description": "This course is addressed to students interested in the logical analysis of complex multi-agent scenarios involving data-exchange and communication. We look at various forms of information flow that can affect both the individual knowledge and the group knowledge of interacting agents. These scenarios include acts by which individuals or groups can publicly or privately access whole databases and `grab’ (read, copy, transmit or modify) all the information stored in them (including numerical, or other non-propositional, data). We present a family of dynamic logics, based on extensions of Dynamic Epistemic Logic that can handle exchanges in which the relevant data are not necessarily in propositional form. We study the expressive power of data-exchange logics, provide complete axiomatizations, show their decidability, and apply them to a range of examples, including sharing an internet resource, learning another agent’s password, hacking a private database, detecting a cryptographic attack, etc.",
          "id": "61",
        },
        {
          "lecturer": "Yanjing Wang",
          "title": "Introduction to Bundled Modalities",
          "group": "Advanced",
          "description": "Bundled modalities pack a quantifier and a modality together. In this course, I will introduce the idea, techniques, and applications of bundled modalities in epistemic logic, deontic logic, non-classical logic, and decidable fragments of first-order modal logic.",
          "id": "35"
        }
      ],
      [
      ]
    ]
  }
]

week2 = [
  {
    "time": "9.00am - 10.30am",
    "groups": [
      [
        {
          "lecturer": "Bart Geurts",
          "title": "Common ground",
          "group": "Foundational",
          "description": "Common ground has been a central notion in theoretical pragmatics since the 1970s, and a fixture in theories of presupposition, reference, speech acts, implicature, and many other topics. Given that pragmatics is an interdisciplinary concern, it is hardly surprising that common ground has been discussed across a range of disciplines, including philosophy, linguistics, psychology, and computer science. But for all its importance, there has been relatively little discussion of foundational issues. Stalnaker (2002, 2014) is a notable exception, but he only discusses his own view. There are radically different views on the nature of common ground, i.e. what common ground IS, and there have been no attempts to compare and contrast these views at any length, and consider their implications for the analysis of speech acts and fiction, for example.  In brief, that is the  objective of this course.",
          "id": "2-0",
          "note": "CANCELLED"
        },
        {
          "lecturer": "Niki Pfeifer",
          "title": "Probability logic, language, and cognition",
          "group": "Introductory",
          "description": "Uncertainty is ubiquitous in everyday life communication and reasoning. In this course, we will learn methods and tools to understand language and cognition under uncertainty. We will get interdisciplinary perspectives by combining formal-philosophical and experimental-psychological approaches. In particular, we will understand why coherence-based probability logic offers a unified rationality framework for studying diverse phenomena including conditionals, counterfactuals, connexivity, quantification, reasoning, and argumentation on the normative level. Moreover, on the descriptive level, we will become familiar with recent experimental-psychological results on linguistic phenomena, cognition, and reasoning under uncertainty. Specifically, we will learn about formal and experimental work on nonmonotonic reasoning, conditionals, counterfactuals, quantification, connexivity, and argumentation. Finally, we will achieve a deeper understanding of what it means to be rational under incomplete knowledge and uncertainty.",
          "id": "2-1",
          "room": "P01"
        }
      ],
      [
        {
          "lecturer": "Bruno Guillaume and Kim Gerdes",
          "title": "Treebanking: methodology, tools and applications",
          "group": "Introductory",
          "description": "This introductory course will present a general introduction to dependency-based syntactic treebanks and to two existing frameworks: Universal Dependencies (UD) and its variant Surface Syntactic Universal Dependencies (SUD). After the general introduction of the topic, we will describe a set of tools that are available to help the development of new treebanks (Grew-match and Arborator-grew), with a focus on under-resourced languages. We present some experiments applying these tools to the construction of new treebanks of Spoken French, Zaar, and Beja. Finally, we will illustrate a few applications which are currently developed in the Autogramm project. One application is the automatic extraction of grammatical observations  from treebanks to help linguists in the study of the grammar of new languages (with an example of Wolof). A second application, the use of these annotated treebanks in quantitative typology will be presented.",
          "id": "2-2"
        },
        {
          "lecturer": "Ryan Cotterell",
          "title": "Formal Language Theory and Neural Networks",
          "group": "Advanced",
          "description": "This tutorial is a comprehensive introduction to neural networks, focusing on recurrent neural networks (RNNs) and transformers, and their relationship to formal language theory. We teach how tools from weighted formal language theory can be useful for understanding the inner workings of and predicting the generalization of modern neural architectures. Over the course of five days, we will explore the theoretical properties of RNNs and their representational capacity in relation to different levels of the weighted Chomsky hierarchy, starting with finite-state automata and the special case of bounded-depth hierarchical languages, and then move on to more complex formalisms such as context-free languages and Turing machines. We will prove multiple theoretical properties of RNNs, including the fact that simple RNNs with infinite precision arithmetic and unbounded computation time can emulate a Turing machine and show how RNNs can optimally represent finite-state automata. Finally, we will discuss recent results in the study of Transformer-based language models from the perspective of formal language theory. Finally, we will discuss the implications of these results for the analysis and practical deployment of language models.",
          "id": "2-10",
          "room": "P22"
        }
      ],
      [
        {
          "lecturer": "Rustam Galimullin and Louwe B. Kuijer",
          "title": "Quantification in Dynamic Epistemic Logic",
          "group": "Introductory",
          "description": "Dynamic epistemic logics (DELs) allow one to reason about how knowledge of agents evolves as a result of various information-changing events. Some of the notable examples of DELs include public announcement logic, arrow update logic, and action model logic. Adding quantification over epistemic events in those DELs shifts the perspective from the effects of a particular event to the question of (non-)existence of an event leading to some epistemic outcome. For example, we may want to verify that there is a communication between Alice and Bob such that they both learn some secret, while eavesdropper Eve remains unaware of the secret. In the course, we will present some of the more well-known DELs with quantification and provide highlights of the proofs behind significant technical results. Moreover, we will also discuss some of the tantalising open question spanning the landscape of logics with quantification over information change.",
          "id": "2-4",
          "website": "https://rgalimullin.gitlab.io/esslli23.html",
          "course-material": [
            {"title": "Course website", "link": "https://rgalimullin.gitlab.io/esslli23.html"}
          ],
        },
        {
          "lecturer": "Beniamino Accattoli",
          "title": "Time and Space for the lambda Calculus",
          "group": "Advanced",
          "description": "The lambda calculus is the core model behind functional programs and proof assistants, as well as a formalism for representing the proofs of intuitionistic logic.  Finding reasonable time and space complexity measures for the lambda calculus, that is, measures that are equivalent to those of Turing machines, have been two long-standing problems, solved only in 2014 (for time) and 2022 (for space).  The course aims at explaining three aspects of this topic: 1) The difficulties behind these problems; 2) The tools to solve them, which are based on an abstract theory of implementations of the lambda calculus; 3) How the time and space cost of terms can be captured via type systems for lambda-terms, namely via multi types, a variant of standard type systems for the lambda-calculus.",
          "id": "2-5"
        }
      ],
      [
        {
          "lecturer": "Valentin Goranko and Dmitry Shkatov",
          "title": "First-order Modal and Temporal Logics: state of the art and perspectives",
          "group": "Workshop",
          "website": "https://dshkatov.github.io/fomtl2023/",
          "description": "First-order modal and temporal logics are of fundamental importance for reasoning about necessity, possibility, and temporality. They offer a broad range of actual and potential applications to philosophy, artificial intelligence, computer science, cognitive science, and linguistics.\nThe workshop is intended to bring together researchers and graduate students in the field of first-order modal and temporal logics, to present the state of the art in the field and to discuss the most important directions for future work in the area.",
          "id": "2-6",
          "room": "P20"
        }
      ]
    ]
  },
  {
    "time": "10.30am - 11.00am",
    "groups": [],
    "title": "coffee break"
  },
  {
    "time": "11.00am - 12.30pm",
    "groups": [
      [
        {
          "lecturer": "Elin McCready and Grégoire Winterstein",
          "title": "Communitarian Semantics",
          "group": "Introductory",
          "description": "In the past 15 years, the study of linguistic expressions with meanings keyed to social domains has taken off in linguistics and philosophy. Empirical domains include slurs, gendered expressions, honorifics, discourse markers, and sociolinguistic indexicals, among others; phenomena include epistemic injustice, standpoints, argumentation, and dogwhistling, among others. The aim of this course is twofold: first, to introduce recent developments in this area to students together with the technical tools, both formal and computational, that have been used to analyze them, and, second, to give a birds-eye view of the study of meaning that situates work in this area in the broader semantic landscape.",
          "id": "2-7"
        },
        {
          "lecturer": "Luka Crnic and Yosef Grodzinsky",
          "title": "Monotonicity: Grammar, Processing, and Neural Reflections",
          "group": "Advanced",
          "description": "​​One of the main discoveries of linguistic theory has been that grammar is sensitive to the monotonicity properties of the objects it generates. A related discovery in experimental (neuro)linguistics has been that the monotonicity properties of linguistic objects also affect their processing, and appear to be neuroanatomically localized. We plan to focus on polarity items and quantification more generally. On the empirical side, we will examine how monotonicity impacts grammatical operations, their processing, and their neural reflexes. On the methodological side, we will consider how theoretical and experimental methods can and should be jointly employed to address these questions.",
          "id": "2-8"
        }
      ],
      [
        {
          "lecturer": "John P. McCrae",
          "title": "Introduction to Linguistic Data Science",
          "group": "Introductory",
          "description": "Big data is fundamentally changing the way that linguists can investigate linguistic facts leading to a new research area which combines data science with linguistics. This course provides an introduction to the new area of linguistic data science by means of an introductory course with hands-on data analysis that is focused on key questions in linguistics. This course will first provide a basic introduction to data science and in particular how this can be applied to large corpora using natural language processing techniques. We will then show how this can be used to find answers to problems in syntax, semantics, multilinguality and other areas of linguistics, along with a summary giving perspectives on how these methods can be applied to students' own research.",
          "id": "2-9",
          "room": "P01"
        },
        {
          "lecturer": "Lidia Pivovarova and Andrey Kutuzov",
          "title": "Computational approaches to semantic change detection",
          "group": "Advanced",
          "description": "During the last three years, automatic detection of language change has been intensified by the introduction of several datasets manually annotated for this task, and by a series of shared tasks. However, a gap still exists between theoretic understanding of various linguistic phenomena contributing to language change and abilities of computational methods to capture these phenomena. The goal of this course is to provide a broad overview of this novel research area and discuss in detail various methods used to detect word meaning shift. We will also discuss open problems and possible practical applications. Every day of the course will feature a lecture and a small practice session. The course will allow students to start working in this research area.",
          "id": "2-3",
          "course-material": [
            {"title": "Course GitHub", "link": "https://github.com/lmphcs/semshift_esslli2023"}
          ],
        }
      ],
      [
        {
          "lecturer": "Matteo Acclavio and Paolo Pistone",
          "title": "An Introduction to Proof Equivalence",
          "group": "Introductory",
          "description": "The goal of this course is to provide an overview on important results and current research trends in proof theory around the notion of proof equivalence. This is the problem of understanding when two formal derivations represent ``the same'' proof, both intuitively and in more precise semantical terms. The search for more canonical representations of logical arguments has lead to the design of new proof systems based on ideas from graph theory or category theory.  Research on proof equivalence has received considerable attention in the proof-theory community, and has led in recent years to several applications in computer science (e.g. for program equivalence or proof-search). However, a structured presentation of fundamental results and perspectives in this area is still missing, and we consider this course as a first step in the direction of filling this gap.",
          "id": "2-11",
          "room": "P22"
        },
        {
          "lecturer": "Balder ten Cate and Carsten Lutz",
          "title": "Logic, Data Examples, and Learning",
          "group": "Introductory",
          "description": "In logic, data examples are useful when a logical formula must be  synthesized or communicated. This includes tasks such as  the reverse engineering of logical queries, debugging and refinement  of formal specifications, as well as various forms of learning.\nThis course provides a uniform introduction to the use of data examples in logic, covering logical formalisms that range from propositional logic  to first-order logic (including conjunctive queries and description logics), and addressing the following questions:\n* When, and to what extent, can a logical formula be described by a    small number of data examples. (\"From Formulas to Data Examples\")\n* How to construct a fitting formula from a set of data examples?    When more than one fitting formula exists, which one should be    preferred?  (\"From Data Examples to Formulas\")\n* When is a fitting formula likely to generalize from input examples to     unseen data examples, and how many input examples are     required to achieve this? (\"PAC Learning\")\n* In interactive design and refinement systems, data examples provide     a means of communication between the system and the user. This    can be modeled as an interactive learning setting with a learner and    an oracle. When is efficient interactive learning of this type possible?",
          "id": "2-12",
          "room": "PB"
        }
      ],
      [
        {
          "lecturer": "Michael Moortgat and Mehrnoosh Sadrzadeh",
          "title": "Modalities in substructural logics: Applications at the interfaces of logic, language and computation (Monday and Tuesday only)",
          "group": "Workshop",
          "website": "https://sites.google.com/view/esslli2023course/workshop",
          "description": "By calling into question the implicit structural rules that are taken for granted in classical logic, substructural logics have brought to the fore new forms of reasoning with applications in many interdisciplinary areas of interest. Modalities, in the substructural setting, provide the tools to control and finetune the logical resource management. The workshop explores the uses of substructural modalities in areas where logic meets linguistics and computer science. The workshop is supported by the EU-funded MOSAIC project (Modalities in Substructural Logics: Theory, Methods and Applications). A complementary proposed course is \"Modal Lambek Calculus and its Natural Language Applications\".\n<b>Resources:</b><ul style=\"margin-left: 2em;\"><li><a href=\"https://sites.google.com/view/esslli2023course/workshop\" target=\"_blank\">Workshop website</a></li><li><a href=\"https://easychair.org/cfp/AMSLO23\" target=\"_blank\">EasyChair</a></li></ul>",
          "id": "2-13"
        }
      ]
    ]
  },
  {
    "time": "12.30pm - 2.00pm",
    "groups": [],
    "title": "lunch"
  },
  {
    "time": "2.00pm - 3.30pm",
    "groups": [
      [
        {
          "lecturer": "Annemarie van Dooren and Anouk Dieuleveut",
          "title": "Decomposing the meaning of modals",
          "group": "Foundational",
          "description": "Modal statements, like “The keys must be in the drawer” or “We must take the train”, involve a complex interplay of syntax, semantics, and pragmatics. The goal of this introductory class is to understand how we can decompose the meaning of modal words like can or must, by going through their standard quantificational analysis inherited from modal logic, with particular attention to the work of Kratzer. The class will combine insights from various disciplines: logic, philosophy and formal semantic theories of modality, cross-linguistic fieldwork, psycholinguistics experiments, and language acquisition.",
          "id": "2-14"
        },
        {
          "lecturer": "Cornelia Ebert and Markus Steinbach",
          "title": "The semantics of visual communication. Theoretical approaches to visual meaning aspects in co-speech gestures and sign language",
          "group": "Advanced",
          "description": "In recent formal semantic research, both sign language and co-speech gestures have been analyzed by applying the theories established for spoken languages to visual meaning aspects. Only little attention has been paid to modelling the specific properties of the visual transmission channel. However, it is now becoming evident that the formal linguistic repertoire needs to be extended to meet the modality-specific requirements of visual communication such as the higher degree of iconicity of gestures and signs, the systematic use of the body of the speaker or signer and the space in front of the body to express, for instance, logical variables, comparative constructions, tense, topographic relations or context shift and the option to demonstrate actions and events. In this class, we will discuss selected examples illustrating the expressive power of visible communication and discuss recent formal accounts that enhance the formal linguistic apparatus to develop formally precise theories that can deal with and model the semantics of visual and multimodal communication.",
          "id": "2-15"
        }
      ],
      [
        {
          "lecturer": "Timothée Bernard and Pascal Amsili",
          "title": "Natural language syntax: parsing and complexity",
          "group": "Foundational",
          "description": "This course aims to provide an introduction to the fields of formal grammars and syntactic parsing, with a focus on their application to natural language. We introduce the concepts of formal language, formal grammar and automaton, and the notion of complexity reflected by the Chomsky-Schützenberger hierarchy. We present how natural language and popular syntactic formalisms fit into this picture. We review at length the evolution of parsing algorithms for natural language, from the classic chart-based paradigm to contemporary shift-reduce parsers, graph-based algorithms, and CCG parsing. We discuss the impact on the field of the advances in machine-learning and introduce some of the key aspects of neural-based parsers and in particular the use of the vector representations of linguistic units produced by language models.",
          "id": "2-16"
        },
        {
          "lecturer": "Martha Palmer and James Pustejovsky",
          "title": "A Uniform Meaning Representation for NLP Systems",
          "group": "Advanced",
          "description": "Impressive progress has been made in many aspects of natural language processing (NLP) in recent years. Most notably, the achievements of transformer-based large language models such as ChatGPT would seem to obviate the need for any type of semantic representation beyond what can be encoded as contextualized word embeddings of surface text. Advances have been particularly notable in areas where large training data sets exist and it is advantageous to build an end-to-end training architecture without resorting to intermediate representations. For any truly interactive NLP applications, however, a more complete understanding of the information conveyed by each sentence is needed to advance the state of the art. Here \"understanding'' entails the use of some form of meaning representation. NLP techniques that can accurately capture the required elements of the meaning of each utterance in a formal representation are critical to making progress in these areas and have long been a central goal of the field.\nAs with end-to-end NLP applications, the dominant approach for deriving meaning representations from raw textual data is through the use of machine learning and appropriate training data. This allows the development of systems that can assign appropriate meaning representations to previously unseen sentences. Generating training data that represents meaning, however, is a very different undertaking from collecting human translated text or transcribed speech as it is not ``naturally occurring.'' It requires the development of a consensus on formal meaning representations that can be used by humans to annotate significant amounts of data for the sole purpose of training the machine learning algorithms.  This has been an elusive target because it is a delicate balancing act between a number of factors. It must provide fair and equal treatment for multiple languages, be intuitive enough to enable fast, consistent human annotation, and support the training of accurate, useful automatic modules that work well in downstream applications.  A meaning representation that strikes the right balance would solve one of the long-standing intellectual problems in the field and  have a transformative effect on NLP specifically, and on Artificial Intelligence in general.\nIn this course, we describe the framework of Uniform Meaning Representations (UMRs), a recent cross-lingual, multi-sentence incarnation of Abstract Meaning Representations (AMRs), that addresses these issues and comprises such a transformative representation. Incorporating Named Entity tagging, discourse relations, intra-sentential coreference, a partial treatment of negation and modality, and the popular PropBank-style predicate argument structures with semantic role labels, into a single directed acyclic graph structure,  UMR builds on AMR and keeps the essential characteristics of AMR while making it cross-lingual and extending it to a document-level representation.\nWe introduce the basic structural representation of UMR and describe its application to multiple languages. We present a formal semantic interpretation of UMR incorporating a continuation-based semantics for scope phenomena involving modality, negation, and quantification. We describe how UMR encodes TAM (Tense Aspect Modality) information in multiple languages. We describe parsing algorithms that generate AMR and UMR representations over multiple languages. Finally, we introduce an extension to UMR for encoding gesture in multimodal dialogue, Gesture AMR (GAMR), which aligns with speech-based UMR to account for situated grounding in dialogue.",
          "id": "2-17",
          "room": "P01"
        }
      ],
      [
        {
          "lecturer": "Giulio Guerrieri",
          "title": "The lambda-calculus: from simple types to non-idempotent intersection types",
          "group": "Introductory",
          "description": "The (pure, untyped) lambda-calculus is a Turing-complete model of computation, simply based on function abstraction and application using variable binding and substitution. Thanks to thesimplicity of the formal system, it is well suited for theoretical investigations in mathematical logic, categorical theory, computability and even complexity. On the other hand, the lambda-calculus is at the core of many functional programming languages (such as LISP, Haskell, OCaml) and proof-assistants (such as Coq and Agda).\nThere are many variants of the lambda-calculus where functions can be applied only if they are capable of accepting the given input's \"type\" of data. Typed lambda-calculi are weaker than the untyped lambda calculus, in the sense that the former can express less than the latter can, but on the other hand typed lambda-calculi can only represent \"well-behaved\" programs, in that \"well-typed programs cannot go wrong\" (R. Milner).\nIn this course we investigate two typed versions of the lambda-calculus. The first one is the simply typed lambda-calculus, which is the computational counterpart--via Curry-Howard correspondence--of natural deduction for intuitionistic propositional logic. We will show that there every evaluation strategy terminates (strong normalization) for every simply typed lambda-term, but the type system is too restrictive because there are \"well-behaved\" programs that cannot be represented there.\nThe second typed variant of the lambda-calculus we will study is the one endowed with a non-idempotent intersection type system. Such a type system increase the typability power of simple types by introducing a new intersection type constructor ∧, which commutative, associative and non-idempotent (A ∧ A is not equivalent to A). The intuition is that term of type A ∧ A ∧ B can be seen as a resource that, during execution, can be used once as a data of type B and twice as a data of type A. Non-idempotent intersection types constitute a powerful tool to reason about qualitative semantic properties of programs: we will show that they characterize different notions of termination in the lambda-calculus, for different notions of evaluation. In this respect, non-idempotent intersection types are able to capture all and only the \"well-behaved\" programs, if we assume that a \"good behavior\" is the fact that evaluation terminates. Moreover, they not only provide qualitative characterization of operational properties, but also quantitative ones, in the sense that any type derivation of a term gives a bound to the execution time for that term (the number of steps to reach a normal form).",
          "id": "2-18",
          "room": "P22",
          "website": "https://pageperso.lis-lab.fr/~giulio.guerrieri/ESSLLI2023.html",
          "course-material": [
            {"title": "Course website", "link": "https://pageperso.lis-lab.fr/~giulio.guerrieri/ESSLLI2023.html"}
          ]
        },
        {
          "lecturer": "Anupam Das",
          "title": "Proof theory of arithmetic",
          "group": "Advanced",
          "description": "This course will introduce students to the fundamentals of the proof theory of arithmetic. We shall assume some previous familiarity with basic proof theory, but will go further to show how to apply these techniques in order to obtain metalogical results of profound importance at the interface between logic and computation. Namely, we shall present a seminal consistency proof of PA via (ordinal-assigned) infinitary cut-elimination, and following on from that derive the famous classification of PA's provably total recursive functions by ordinal recursion. The course will conclude by surveying other consistency proofs and classifications of PA's provably total recursive functions, namely via Goedel's T, a higher-typed of primitive recursion, as well as the adaptation of these results to important fragments and extensions of PA.",
          "id": "2-19",
          "website": "https://www.anupamdas.com/esslli23/"
        }
      ],
      [
        {
          "lecturer": "Michael Moortgat and Mehrnoosh Sadrzadeh",
          "title": "Modalities in substructural logics: Applications at the interfaces of logic, language and computation (Monday and Tuesday only)",
          "group": "Workshop",
          "website": "https://sites.google.com/view/esslli2023course/workshop",
          "id": "2-13"
        }
      ]
    ]
  },
  {
    "time": "3.30pm - 3.50pm",
    "groups": [],
    "title": "coffee break"
  },
  {
    "time": "3.50pm - 4.50pm",
    "groups": [],
    "title": "Student Session (StuS)<br/>Room: PA",
    "link": "courses-workshops-accepted/student-session-call.html"
  },
  {
    "time": "5.00pm - 6.30pm",
    "groups": [
      [
        {
          "lecturer": "Zhaohui Luo",
          "title": "Advanced Topics in Formal Semantics Based on Modern Type Theories",
          "group": "Advanced",
          "description": "Formal semantics based on modern type theories (MTT-semantics) provides us with not only a viable alternative to Montague’s semantics, but potentially an attractive full-blown semantic tool with advantages in many respects. However, the salient features of MTT-semantics may only be discussed properly when more advanced semantic topics are considered. For example, people may ask: how does it fare with semantic issues such as events and anaphoric reference, and could it offer a good treatment of intriguing linguistic features such as copredication? In the past, some of these advanced issues have only been dealt with briefly [1], but more recently they have been studied more in depth in the proposer’s monograph [2]. In this course, after an overview introduction, I shall consider the following topics in MTT-semantics: event semantics, anaphoric references, copredication and dependent categorial grammars. I’ll also compare the treatments with those studied in the Montagovian approach and discuss their respective merits.\n[1] S. Chatzikyriakidis and Z. Luo. Formal Semantics in Modern Type Theories. Wiley/ISTE, 2020. \n[2] Z. Luo. Modern Type Theories: Their Development and Applications. Tsinghua University Press, 2022. In press.",
          "id": "2-20",
          "course-material": [
            {"title": "Course proposal", "link": "https://2023.esslli.eu/images/2023/documents/Formal-Semantics/ESSLLI23proposal.pdf"},
            {"title": "Slides for Lecture I", "link": "https://2023.esslli.eu/images/2023/documents/Formal-Semantics/ESSLLI23slidesL1.pdf"},
            {"title": "Slides for all 5 lectures", "link": "https://www.cs.rhul.ac.uk/home/zhaohui/lecture-notes.html"},
            {"title": "Papers/books on MTT-semantics", "link": "https://www.cs.rhul.ac.uk/home/zhaohui/lexsem.html"}
          ]
        },
        {
          "lecturer": "Patrick Elliott and Lisa Hofmann",
          "title": "Explaining anaphoric accessibility: navigating non-veridical environments in dynamic semantics",
          "group": "Advanced",
          "description": "Classical dynamic accounts of anaphora rely on logical operators arbitrarily manipulating anaphoric information. Alongside conceptual concerns of explanatory (in)adequacy, classical accounts are known to make poor empirical predictions for non-veridical environments (see, e.g., Roberts 1987, Krahmer and Muskens 1995). In this course, we motivate an alternative approach, which treats logical operators as fundamentally truth-functional. In the first half of the course, we explore an approach to anaphora based on the Strong Kleene account of presupposition projection. The initial goal will be to derive and improve upon Groenendijk & Stokhof's (1991) accessibility generalizations, with a particular focus on negation and disjunction. The latter half of the course zooms in on counterfactual content: The initial Strong Kleene account fails to capture key constraints on the (anti)veridicality of anaphorically active content. We revise the account by intensionalizing discourse referents, which are in turn interpreted relative to both a local and a global intensional context.",
          "id": "2-21"
        }
      ],
      [
        {
          "lecturer": "Tim Van de Cruys",
          "title": "Computational Creativity",
          "group": "Introductory",
          "description": "This course provides an introduction to the field of computational creativity. We will examine different approaches to the computational modeling of creativity, and see how they relate to theories of human creativity. The course focuses primarily on computational creativity from a language-oriented perspective. As such, we will examine different applications of creative language generation (such as metaphor, humor, neologisms, poetry, and stories) from a computational perspective. Additionally, cross-modal and multi-modal approaches to computational creativity will be explored. Along the way, we will discuss a number of crucial topics, such as the preconditions of computational creativity, the evaluation of computationally creative systems, and the ethical implications.",
          "id": "2-22",
          "room": "P22"
        },
        {
          "lecturer": "Fausto Carcassi and Michael Franke",
          "title": "The probabilistic Language of Thought",
          "group": "Advanced",
          "description": "Computational modeling of cognition is at the heart of cognitive science. However, our most developed and expensive models, artificial neural networks, struggle to match some striking human skills: few- or zero-shot learning (figuring out a rule from few examples) and manipulating compositionally structured representations and symbols with a rich logical structure. This course focuses on a promising framework to model these human cognitive skills: the probabilistic Language of Thought (LoT). We will start with the philosophical underpinnings of the program in the work of Jerry Fodor. Then, we will discuss recent developments, combining the LoT with probabilistic approaches to learning to develop models of category acquisition across a variety of conceptual domains. This will require a discussion of several technical tools (formal grammars, compositional semantics, Bayesian inference). Finally, we will look at recent promising developments in the field (neurosymbolic learning, the child as a hacker).",
          "id": "2-23"
        }
      ],
      [
        {
          "lecturer": "Louwe B. Kuijer",
          "title": "Conditional logics of preference: how to make the best choice",
          "group": "Introductory",
          "description": "This course is about preference structures. These are versatile models, consisting of a set of alternatives and a relation, denoted <, between them that indicates \"betterness\" or \"preference\" of some kind. The versatility comes from the fact that preferences, and the alternatives that they rank, can mean many things in different contexts.\nThe most straightforward meaning is if < represents a utility comparison of an agent, e.g., \"coffee < tea\". But < could also represent a plausibility ordering (more plausible is \"better\"), a defeat relation among strategies (\"scissors < rock\"), et cetera. By studying preference structure we can improve our understanding of all these different interpretations of <.\nWe will study these structures through the vehicle of conditional logics. These logics have an operator B(p|q), with the meaning that \"if q holds, then p is the best choice\". In particular, we will investigate how B(p|q) depends on assumptions about <.",
          "id": "2-24"
        },
        {
          "lecturer": "Fan Yang",
          "title": "Logics of dependence and independence",
          "group": "Advanced",
          "description": "This course provides a concise introduction to logics of dependence and independence (DIL), which are  formalisms for reasoning about dependence and independence relations in sciences. We will study the novel semantics of DIL -- team semantics. The basic idea of team semantics is that dependency properties can only manifest themselves in multitudes, and thus formulas of DIL are evaluated on sets of assignments (called teams) instead of single assignments as in the usual Tarskian semantics. A team can be naturally viewed as a database, a dataset, an information state, etc. Thanks to the simple structure of teams and the abundance of their interpretations in various fields of science, DIL have found a number of applications in addressing issues in database theory, social choice, quantum theory, formal linguistics, and so on. This course will also discuss recent developments on these applications.",
          "id": "2-25",
          "course-material": [
            {"title": "Course website", "link": "https://sites.google.com/view/dil-esslli23/"}
          ],
          "website": "https://sites.google.com/view/dil-esslli23/"
        }
      ]
    ]
  }
]
