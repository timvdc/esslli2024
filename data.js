evening_lecturers = [
  {
    "lecturer": "Marko Robnik Šikonja",
    "title": "Large language models for cross-lingual transfer",
    "group": "Evening",
    "description": "Currently, the most successful approach to natural language processing is based on large pretrained language models using the transformer architecture of neural networks. These are typically pretrained on huge text corpora on the tasks of predicting next tokens or masked tokens. While most existing models are predominantly monolingual, multilingual variants also exist and can help in cross-lingual transfer of knowledge and models. We will present a few types of large language models, focusing on cross-lingual transfer. We will show their strengths and weaknesses in text classification, summarization, and question answering.",
    "id": "evening1",
    "date": "2023-08-01",
    "time": "19:00-20:30",
    "room": "PA",
    "moderator": "Slavko Žitnik",
    "website": "https://fri.uni-lj.si/en/about-faculty/employees/marko-robnik-sikonja"
  },{
    "lecturer": "Malvina Nissim",
    "title": "Language Technology <preposition> Society",
    "group": "Evening",
    "description": "The recognition of society’s role in language technology has become essential and cannot be overlooked. Still, plenty of research in Natural Language Processing does not explicitly account for such interplay. This evening lecture will zoom in on precisely this aspect. “Precisely” is an ambitious term, since the very definition of the relationship between language technology and society is subject to multiple interpretations, both in the context of scientific research as well as in connection with the general public, who currently is very much exposed to, interested in, and involved with language-based artificial intelligence tools. Through recent work I’ve carried out with my group, and through personal reflections, I will unpack this exciting relationship from different angles.",
    "id": "evening2",
    "date": "2023-08-03",
    "time": "19:00-21:00",
    "room": "PA",
    "moderator": "Valerio Basile",
    "website": "https://malvinanissim.github.io/"
  },{
    "lecturer": "Beniamino Accattoli",
    "title": "The Cost of the lambda Calculus and the Semantics of Sharing",
    "group": "Evening",
    "description": "The lambda calculus is an expressive mathematical formalism that elegantly captures the core of functional programming languages, while providing at the same time compact representations of intuitionistic logic proofs.\nThe first part of the talk shall survey the recent advances in the study of reasonable cost models for the lambda calculus, that is, of time and space cost measures that are equivalent to those of Turing machines. In particular, it shall overview how understanding the role of sharing in the evaluation process is crucial for both time and space, but for opposite reasons.\nThe second part of the talk shall show that extending the lambda calculus with first-class sharing is not a minor extension, as crucial semantic properties and results break, and new tools and richer theories need to be developed.",
    "id": "evening3",
    "date": "2023-08-08",
    "time": "19:00-20:30",
    "room": "PA",
    "moderator": "Valentin Goranko",
    "website": "https://sites.google.com/site/beniaminoaccattoli/"
  },{
    "lecturer": "Darja Fišer",
    "title": "The Good, the Bad and the Ugly of Language Technology Infrastructure",
    "group": "Evening",
    "description": "Advances in digitization and datafication have been transformative for linguistics and other disciplines that work with language materials. This has increased the need for research infrastructures that supports the development, documentation, archiving, dissemination, reuse and citation of language resources and tools which is prerequisite for verifiable, reproducible and ethical research. Still, the potential of research infrastructures in language technology remains undervalued and underutilised in the real world of language-based research and education. Based on the work conducted within my research group as well as through personal observations, I will address the good, the bad and the ugly aspects of adopting the research infrastructure principles that is built around the Open Science and FAIR data paradigm.",
    "id": "evening4",
    "date": "2023-08-10",
    "time": "19:00-21:00",
    "room": "PA",
    "moderator": "John McCrae",
    "website": "https://www.inz.si/en/Scientific-research-department/Darja-Fiser_en/"
  }
]

week1 = [
  {
    "time": "9.00am - 10.30am",
    "groups": [
      [
        {
          "lecturer": "Howard Gregory",
          "title": "Language and Logics",
          "group": "Foundational",
            "description": "This course introduces the use of formal logic in natural language semantics. It has no prerequisites, but an introductory linguistics course is desirable. The coverage will be limited to classical first order logic (FOL). This is far from the only logic used in linguistics, but it is presupposed by most advanced work. FOL is presented in a way which highlights the assumptions and choices made and the plurality of logics (as promised by the title), providing pointers to further directions of study.",
            "id": "1-0"
        },
        {
          "lecturer": "Matthew Mandelkern and Melissa Fusco",
          "title": "Conditionals, probability, and decision",
          "group": "Introductory",
          "description": "This advanced course in Language and Logic will explore interactions between the theory of the conditional and the theory of rational decision. Stalnaker (1971) and many following have argued that there is a close connection between conditionals and rational decision: at a first pass, you should do the act that, in expectation, WOULD bring about the best consequences IF you were to do it. This intuitive picture both constrains, and is constrained by, the theory of the conditional (in particular, its logic and semantics, and corresponding probabilities). The course will explore the interacting perspectives of decision theory (Fusco’s specialty) and conditional semantics (Mandelkern’s specialty).",
          "id": "1-1"
        }
      ],
      [
        {
          "lecturer": "John McCrae",
          "title": "Introduction to Linguistic Data Science ",
          "group": "Foundational",
          "description": "Big data is fundamentally changing the way that linguists can investigate linguistic facts leading to a new research area which combines data science with linguistics. This course provides an introduction to the new area of linguistic data science by means of an introductory course with hands-on data analysis that is focused on key questions in linguistics. This course will first provide a basic introduction to data science and in particular how this can be applied to large corpora using natural language processing techniques. We will then show how this can be used to find answers to problems in syntax, semantics, multilinguality and other areas of linguistics, along with a summary giving perspectives on how these methods can be applied to students’ own research.",
          "id": "1-2",
          "room": "P22"
        },
        {
          "lecturer": "Damir Cavar and Billy Dickson",
          "title": "Generative AI and Symbolic Knowledge Representations: Large Language Models, Knowledge, and Reasoning",
          "group": "Introductory",
          "description": "This course is intended to be an Advanced Course addressing Large Language Models, or in general Large Models (multi-modal) and Knowledge Representations for reasoning and semantic processing. We discuss: - What are knowledge representations? This is about Ontologies, Knowledge Graphs, and semantic web approaches to handle for example Description Logic representations and reasoning. - What are Large Language Models and, ultimately, Large Models? This is mainly addressing so-called Generative AI, approaches to building and training models, and their application and limits, when the input is unstructured text or visual information only. - How can LMs and computational semantics approaches be combined? This addresses general problems of LMs (e.g., hallucinations), and we discuss how symbolic (and also probabilistic) knowledge representations can be linked to LMs generating more reliable responses, summaries, even pragmatic aspects like implicatures and presuppositions. We also discuss how LMs can be trained on knowledge and semantic representations to improve their reasoning capabilities. This course can be accompanied by extensive material, code, and instructions shared with students and the community, including hands-on access to the respective technologies. Depending on the audience, interest, and goals, we can adjust the level and content and design the course to include a discussion of state-of-the-art approaches to the generation of Ontologies, taxonomies, and Knowledge Graph representations. This course might sound technologically challenging, but we can assure you that it is actually within the scope of advanced undergraduate students, certainly appropriate for interested graduate students coming with basic computation experience, knowledge of statistics, and interest in logic, semantics, and knowledge representations.",
          "id": "1-3",
          "room": "P01"
        }
      ],
      [
        {
          "lecturer": "Dan Frumin and Jorge A. Pérez",
          "title": "Propositions as Sessions: Logical Foundations of Concurrent Computation",
          "group": "Foundational",
          "description": "The Curry-Howard(-deBruijn) correspondence, also known under the slogan of \“Propositions as Types\”, is arguably the most important bridge between logic and computation. The connection between intuitionistic logic and lambda-calculus is the most familiar instance of this bridge. The correspondence can be seen as a fruitful principle for logically-informed foundations of programming languages. This introductory course will explore recent work on the Curry-Howard correspondence between substructural logics and concurrent processes, dubbed as \“Propositions as Sessions\”. Following a gradual approach, participants will learn how Girard’s linear logic and its extensions serve as a basis for structuring message-passing concurrent programs through the discipline of session types. No specific prerequisites are assumed for this course, except for familiarity with formal logic; participants will get familiar with the selected topics in Substructural Logics, Concurrency Theory, and Programming Languages. The course will close with an overview of prospective research challenges.",
          "id": "1-4"
        },
        {
          "lecturer": "Balder ten Cate and Frank Wolter",
          "title": "A Modern Introduction to Craig Interpolation",
          "group": "Introductory",
          "description": "Craig interpolants are, intuitively, logical formulas that ``explain'' why an entailment between formulas P and Q holds by reference to the shared vocabulary of P and Q. They nowadays play a fundamental role not only in mathematical and philosophical logic, but also in applied areas ranging from automated deduction to program verification, databases and knowledge representation. They are used, for instance, as explainers of why sets of program states are disjoint and as synthesisers of concepts, programs and queries. The purpose of this course is to introduce the logical foundations and applications of Craig interpolation. We cover formalisms ranging from propositional and first-order logic to description and temporal logic. We illustrate modern applications, focusing on databases and knowledge representation. Finally, we also discuss recent research on what to do if a logic does not enjoy the Craig interpolation property, i.e., when there are entailments without Craig interpolants. We give an an introduction to Craig Interpolation and its modern applications in computer science, including databases, knowledge representation, complexity theory, and program verification.",
          "id": "1-5"
        }
      ],
      []
    ]
  },
  {
    "time": "10.30am - 11.00am",
    "groups": [],
    "title": "coffee break"
  },
  {
    "time": "11.00am - 12.30pm",
    "groups": [
      [
        {
          "lecturer": "Dan Zeman",
          "title": "	The Semantics and Pragmatics of Slurs",
          "group": "Introductory",
          "description": "Whether we like it or not, “bad words” are ubiquitous in natural language. While using such words has sometimes no significant effects, in many cases their use can produce real harm, by denigrating, silencing, and marginalizing the people they target. Slurs are one such type of “bad words”. Most researchers agree that the main function of slurs is that of derogating or dehumanizing, of signalling that their targets are unworthy of equal standing or full respect as persons. Figuring out how slurs achieve their main function is an important topic in contemporary philosophy of language and linguistics. In this introductory course, my aim is to present the main characteristics of slurs and their uses (not limited to derogation), explore the main views on their semantics and pragmatics, and show how they are connected to larger social phenomena like power structures and communal identities.",
          "id": "1-6"
        },
        {
          "lecturer": "Cameron Domenico Kirk-Giannini and Henry Schiller",
          "title": "Speech Acts: Dynamic Force and Conversational Update",
          "group": "Introductory",
          "description": "Stalnaker’s theory of the dynamic effect of assertion treats assertoric updates as intersective functions from one context to another. For Stalnaker, this is the characteristic way in which assertion changes the state of a conversation: its dynamic force. This course will introduce students to work in formal pragmatics on the dynamic force of various speech acts. We’ll begin with an introduction to speech act theory and discourse context, and then introduce Stalnaker’s theory of assertion as well as some challenges to that theory. The next part of the course will consider formal theories of directives and questions. In this section, our aim will be to assess whether we can account for the dynamic effects of these speech acts while remaining within the Stalnakerian model — and if not, how else we might account for those effects. Finally, we’ll turn our attention to topics that push the boundaries of traditional theories of formal pragmatics, such as felicitous underspecification and peripheral content.",
          "id": "1-7"
        }
      ],
      [
        {
          "lecturer": "Mark Steedman",
          "title": "Categorial Foundations of Natural Language Structures",
          "group": "Introductory",
          "description": "The course analyses the problem of natural language structure, as characterized by language diversity, requirements of language acquisition by children, extreme ambiguity, and discontinuity (where elements that seem to belong together semantically are separated in the sentence), in terms of an extension of classical Categorial Grammar. The problem will be analyzed in its own right and from the ground up, without any specifically linguistic theoretical assumptions. However, along the way, links to various existing linguistic and computational theories of language will be established, as needed by the students.",
          "id": "1-8"
        },
        {
          "lecturer": "Andreas Liesenfeld and Mark Dingemanse",
          "title": "Introduction to Conversational AI",
          "group": "Foundational",
          "description": "Conversations come naturally to us. While we humans learn language through conversation, interactive language use is arguably the holy grail of speech and language processing. With large language modelling (LLM) approaches, progress was made towards building more interactive agents. Yet, modelling human-like conversational AI remains a moonshot. This foundational course delves into why modelling conversational competence is so challenging. It also takes stock of recent engineering breakthroughs in building conversational AI systems using instruction-tuned LLM models such as ChatGPT, Llama or Mistral. Students will learn the basics of interactive language modelling and explore the scientific and theoretical foundations of understanding structure and variation in conversational speech data in hands-on tutorials. We will work through recent empirical and computational work on speech corpora, speech recognition, and technology assessment. Aspects of conversational infrastructure covered include turn-taking, interactive repair, and action ascription. We conclude by touching upon societal and ethical issues that emerge alongside the rise of conversational AI. This course might appeal to anyone interested in recent approaches to conversational AI and understanding why talking machines still struggle to hold up their end of a conversation. Some experience working with Python and Jupyter notebook required.",
          "id": "1-9",
        }
      ],
      [
        {
          "lecturer": "Mikhail Rybakov and Dmitry Shkatov",
          "title": "Computational aspects of first-order modal logics",
          "group": "Advanced",
          "description": "The course will introduce students to computational aspects of first-order modal logics. The course will contain a brief, self-contained introduction to first-order modal logics and then will cover the most important techniques for proving decidability, undecidability, and lack of recursive enumerability for first-order modal logics and their fragments. The course is intended for a broad audience of graduate students interested in modal reasoning and its computational aspects. This includes students of logic, philosophy, computer science, linguistics, and mathematics. The course will assume a basic familiarity with the classical first-order logic and with Kripke semantics for propositional modal logics.",
          "id": "1-10",
        },
        {
          "lecturer": "Valentin Goranko",
          "title": "Games Logicians Play",
          "group": "Advanced",
          "description": "This course will introduce, discuss and illustrate with examples the most important games in logic, including: dialogue argumentation games, evaluation games, model building games, and model comparison games. These games can be used for model checking, constructive satisfiability testing, to characterize logical equivalences of models, and to prove non-definability results. Optionally, I will also introduce and discuss game-theoretic semantics with incomplete information for logical languages.",
          "website": "Course webpage can be found at https://www2.philosophy.su.se/goranko/Courses2024/ESSLLI2024_GamesLogiciansPlay.html",
          "id": "1-11"
        }
      ],
      [
        {
          "lecturer": "Carla Umbach and Yael Greenberg",
          "title": "Incremental constructions within and across languages: Where degrees, eventualities and discourse dynamics interact",
          "group": "Workshop",
          "website": "placeholder",
          "description": "Incrementality ('adding up to a larger whole', König 1991) can be expressed by English 'more' (1), German 'noch/mehr', Hebrew 'od', Mandarin 'hai' etc. (1) Some/3 kids sang at the party. Then some/3 more kids danced. While studies of individual incremental constructions (INCRs) exist, there are still many gaps in their understanding. This workshop aims to fill such gaps (A) by studying how INCRs syntactically and semantically vary, both across and within languages, and (B) by trying to integrate insights from two approaches to incrementality, which thus far have not interacted: Degree-based approaches (e.g. Greenberg 2010, Thomas 2011), taking INCRs to express additive measurements of eventualities, and discourse-based approaches (e.g. Eckardt 2007, Umbach 2012, Grubic 2018) taking INCRs to be focus/QUD-sensitive, managing the growth of information along discourse-salient dimensions (e.g. event/discourse time). The topic of this workshop is closely related to that of the Week 1 course on 'Scalarity and Additivity in Natural Language'. Course participants are welcome.",
          "id": "1-12",
        }
      ]
    ]
  },
  {
    "time": "12.30pm - 2.00pm",
    "groups": [],
    "title": "lunch"
  },
  {
    "time": "2.00pm - 3.30pm",
    "groups": [
      [
        {
          "lecturer": "Merel Semeijn and Louis Rouillé",
          "title": "Let’s talk about Frodo: An Introduction to the Semantics of Fiction",
          "group": "Introductory",
          "description": "Providing a semantic theory that applies to both serious and fictional uses of language is challenging. Fiction is about pretence, or make-believe: when we produce or interpret a fictional text, we typically read fictional statements as if they were true by imagining a fictional world. A good semantics of fiction should model how this pretence component operates both at the sentential level (what is \"truth in the fiction\" as opposed to truth simpliciter?) and at the level of reference (what is the semantic contribution of a fictional name as opposed to a real name?). This course will take students into the very active and growing area of research today concerned with providing a good semantics of fiction. This field contains many open problems. It is essentially interdisciplinary (at the intersection of philosophy of language, formal linguistics, logic and literary studies) and it questions the foundations of our best semantic theories.",
          "id": "1-13"
        },
        {
          "lecturer": "Keny Chatain and Benjamin Spector",
          "title": "Current topics in the semantics and pragmatics of plural expressions",
          "group": "Advanced",
          "description": "What is the meaning of plural expressions in natural languages: \"the students\", \"some apples\", etc? While the answer to such questions seems pretty straightforward at first sight, appearances are deceptive. It turns out that providing a unified and empirically adequate theory of the meaning of plural expressions  in various syntactic environments is surprisingly difficult.\nThe goal of this class is to introduce students to one major approach to plural semantics, based on the the idea that plural expressions denote or quantify over so-called \"plural individuals\", and to present some recent research within this framework which aim to address puzzles pertaining to the interpretation of numerals and plural definites. The discussion will contain the presentation of formal models, a detailed investigation of their predictions, as well as data coming from experimental semantics. We will cover topics such as:\n- The various types of readings that plural expressions can trigger depending on the type of predicate they combine with (collective readings, distributive readings, cumulative) - Typology of collective predicates (gather/numerous) - Maximality in the semantics of plural quantifiers (all, modified numerals) and its interaction with predicate types - Homogeneity and non-maximality",
          "id": "1-14"
        }
      ],
      [
        {
          "lecturer": "Mehrnoosh Sadrzadeh and Gijs Wijnholds",
          "title": "Natural Language Syntax and Statistical Semantics with Modal Lambek Calculus",
          "group": "Introductory",
          "description": "The Lambek Calculus models natural language grammar as a logic, rejecting the rules of commutativity, associativity, contraction and weakening. Controlled versions of these rules can be added via modalities and the resulting logic is known as Modal Lambek Calculus. Modal Lambek Calculus has a compositional interface to natural language semantics: to possible worlds via ternary frames, and to vector representations via  algebraic constructions over syntax.\nThis course has two parts. The first part covers the core methodology behind the  modelling with Lambek Calculus and its modal extensions; we derive examples of syntactic constructions and analyse their semantics. After that, we focus on the vector semantics and  show how they are learnt via statistical machine learning, applying the results to semantic similarity and disambiguation tasks. Along the way, we offer the possibility to work with user-friendly tools that produce syntactic derivations and compute statistical representations, and datasets for empirical validations/applications.",
          "id": "1-15",
          "room": "P20",
          "website": "https://sites.google.com/view/esslli2023course",
          "course-material": [
            {"title": "Course website", "link": "https://sites.google.com/view/esslli2023course"}
          ]
        },
        {
          "lecturer": "Michael Roth",
          "title": "Limitations in NLP: Disagreements, Misunderstandings, and other Challenges",
          "group": "Advanced",
          "description": "Most approaches to natural language processing assume that language is consistently unambiguous: there is always only one right answer to a question, each sentence has exactly one specific meaning, and text classification tasks generally have only one correct solution. But do these assumptions really hold up in reality? A growing body of research is examining the fact that questions can be answered differently, texts can be understood in various ways, and annotators in general can have conflicting opinions.\nIn this advanced course, we will take a closer look at some of the difficulties that arise from the inherent ambiguity of language. In the first half of the course, we will introduce different types of challenges and corresponding tasks proposed in the literature. In the second half of the course, we will discuss possible solutions from recent research as well as natural limitations that might remain for computational models of language.",
          "id": "1-16",
          "room": "P01"
        }
      ],
      [
        {
          "lecturer": "Aleks Knoks and Eric Pacuit",
          "title": "Tools for Formal Epistemology: Doxastic Logic, Probability and Default Logic",
          "group": "Foundational",
          "description": "Logicians, philosophers, and artificial intelligence researchers interested in epistemic questions---or, roughly, questions relating to belief, knowledge, and reasoning---have developed formal models to refine these questions and to answer them. This course will introduce three of the most prominent such formal models: doxastic logic, Bayesian models, and default logic. We will introduce these models, highlighting their similarities and differences, as well as their advantages and pitfalls. The course will touch on the fundamental questions driving much of the research in formal epistemology. In addition to presenting the different models, we will discuss such issues as the lottery and preface paradoxes, doxastic paradoxes, the source of epistemic normativity, and puzzles associated with higher-order evidence and peer disagreement.",
          "id": "1-17",
          "room": "PB"
        },
        {
          "lecturer": "Valentin Goranko and Dmitry Shkatov",
          "title": "First-order Modal and Temporal Logics: Philosophical and Computational Aspects",
          "website": "https://www2.philosophy.su.se/goranko/Courses2023/ESSLLI2023.html",
          "group": "Advanced",
          "description": "This course will introduce languages, models, main types of semantics, and deductive systems for first-order modal and temporal logics.  It will discuss the philosophical problems arising in the interaction of quantification with modality and temporality and will then present an overview of technical results on completeness and incompleteness, decidability and undecidability, as well as algorithmic and computational complexity of the decision problems for some important systems of first-order modal and temporal logics.  Applications to philosophy, mathematics, and computer science will be briefly discussed.\nThe course is intended for a broad audience of graduate students interested in logical, philosophical, and computational aspects of modal and temporal reasoning.",
          "course-material": [
            {"title": "Course website", "link": "https://www2.philosophy.su.se/goranko/Courses2023/ESSLLI2023.html"}
          ],
          "id": "1-24",
          "room": "P22"
        }
      ]
    ]
  },
  {
    "time": "3.30pm - 3.50pm",
    "groups": [],
    "title": "coffee break"
  },
  {
    "time": "3.50pm - 4.50pm",
    "groups": [],
    "title": "Student Session (StuS)<br/>Room: PA",
    "link": "courses-workshops-accepted/student-session-call.html"
  },
  {
    "time": "5.00pm - 6.30pm",
    "groups": [
      [
        {
          "lecturer": "Peter Fritz",
          "title": "Propositional Quantifiers",
          "group": "Introductory",
          "description": "Propositional quantifiers are quantifiers binding variables in the position of sentences. For instance, when added to standard propositional logic, they allow us to express the claim that for every proposition p, there is a proposition q such that p is materially equivalent to the negation of q.\nThis course will focus on propositional quantifiers in the context of modal logics, where they are especially useful. For example, in the context of a doxastic interpretation of modal logic, they allow us to make generalizations about what is and is not believed by an agent. With this, we can state that everything the agent believes is the case, that the agent believes that they believe something false, or that everything believed by one agent is believed by a second agent.\nStandard possible world models for modal logics can be extended straightforwardly to propositional quantifiers, by letting these quantifiers range over arbitrary sets of worlds. However, in many cases, this straightforward model theory leads to logics which are not recursively axiomatizable. In addition to these simple models, we will therefore consider a range of alternative models, including models based on complete Boolean algebras, and possible worlds models in which propositional quantifiers range over a restricted domain of sets of worlds.\nThe aim of the course is to show the usefulness of propositional quantifiers in modal logics using examples, to provide a systematic overview of the work that has been done in this field, and to highlight some of the many interesting questions which remain open.\nThe course level will be Introductory.",
          "id": "1-19"
        },
        {
          "lecturer": "Yoad Winter",
          "title": "The Semantics of Reciprocity",
          "group": "Advanced",
          "description": "The proposed course will provide an overview of reciprocity from logical and (cross-)linguistic perspectives. After a short introduction to the formal semantics of plurals, the first part of the course will analyze meanings of reciprocal quantifiers (‘each other’). We will address their cross-linguistic relations with distributivity and collectivity, anaphora and reflexivity, and analyze pragmatic and lexical effects on their selection. The second part of the course will discuss reciprocal predicates (‘meet’, ‘hug’, ‘friend’), their logical effects on symmetry of n-ary relational meanings, and conceptual interactions with events and thematic roles. Overall, the proposed course will serve as an up-to-date example of the heterogeneity of formal semantics, illustrating its development from a subfield of philosophical logic to an interdisciplinary domain in linguistics that also engages with syntactic theory, lexical and typological analysis, and psycholinguistics.",
          "course-material": [
            {"title": "Course slides", "link": "https://www.phil.uu.nl/~yoad/esslli2023-course.pdf"}
          ],
          "id": "1-20"
        }
      ],
      [
        {
          "lecturer": "Eric Pacuit",
          "title": "Computational Game Theory in Julia",
          "group": "Introductory",
          "description": "There are two objectives for this course. The first objective is to introduce the Julia programming language, with a special focus on developing programs to study game theory using the Agents.jl package (https://juliadynamics.github.io/Agents.jl) and the GameTheory.jl package (https://quantecon.github.io/GameTheory.jl). The second objective is to provide an introduction to game theory emphasizing issues of particular relevance to students at ESSLLI, such as signaling games and repeated games on networks. The course will include a number of tutorials that will give students hands-on experience writing Julia programs. No previous experience with the Julia programming language will be assumed.",
          "id": "1-21",
          "room": "P01"
        },
        {
          "lecturer": "Kyle Richardson and Vivek Srikumar",
          "title": "Formal Techniques for Neural-symbolic Modeling",
          "group": "Advanced",
          "description": "This is intended to be an advanced course on current methods for combining symbolic logic and neural networks, with applications to problems in natural language processing (NLP). In particular, we focus on techniques that use  symbolic knowledge and declarative constraints to train machine learning models by compiling the corresponding symbolic logic into a differentiable form, also known as the logic as a loss function family of approaches. Details of current approach in NLP, as well as the formal and algorithmic techniques needed to doing this, will be covered in detail and drawn from the broader literature of neural-symbolic learning and reasoning.",
          "id": "1-22"
        }
      ],
      [
        {
          "lecturer": "Wesley Holliday",
          "title": "Possibility Semantics",
          "group": "Introductory",
          "description": "Possibility Semantics is a generalization of Possible World Semantics, based on partial possibilities instead of complete possible worlds. In recent years, this approach has been applied to the semantics of modal and non-classical logics, natural language semantics, and semi-constructive mathematics. In this course, we will provide: a more accessible introduction to Possibility Semantics than is available in the technical literature (Day 1); in-depth sample applications of Possibility Semantics to the formal semantics of epistemic modals in natural language (Days 2-3), the modeling of knowledge and awareness (Day 4), temporal logic and the openness of the future (Day 5), and an introduction to propositional and first-order quantification in possibility semantics (Day 5, time permitting). No previous familiarity with Possibility Semantics will be assumed. Over the course of the week, we will suggest a number of open problems and avenues for future research.",
          "id": "1-23",
          "website": "https://sites.google.com/site/wesholliday/research/modality/modal-logic/possibility-semantics-esslli-2023",
          "course-material": [
            {"title": "Course website", "link": "https://sites.google.com/site/wesholliday/research/modality/modal-logic/possibility-semantics-esslli-2023"}
          ],
          "room": "P22"
        },
        {
          "lecturer": "Brian Logan",
          "title": "Logics for Safe AI (course supported by EurAI)",
          "group": "Advanced",
          "description": "This advanced course will introduce the use of logics for the specification, verification and synthesis of provably correct AI programs. The topics will range from verification of multi-agent systems, synthesis of strategies for coalitions of agents, the use of logic in ensuring safety properties in reinforcement learning, and synthesising reward functions in reinforcement learning from logical specifications.",
          "id": "1-18"
        },
        {
          "lecturer": "Nebojša Ikodinović and Dragan Doder",
          "title": "Logics with Probability Operators and Quantifiers",
          "group": "Advanced",
          "description": "Many formalisms for representing, and reasoning with, uncertain knowledge are based on probabilistic logics that extend classical logic calculus with probability operators or quantifiers. The main goal of this course is to provide a solid foundation for students that want to use results and ideas from probabilistic logics  in their own field of study. We will introduce inductive logic, predicate logic with probability quantifiers and several logics with probability operators through a variety of examples from different fields (philosophy, decision theory, artificial intelligence, game theory etc.), and a more detailed presentation of related research problems (Specify some principles of rational belief and find their mathematical representation; Investigate logical consequence of the law of large number; Axiomatize propositional logic related to Markov processes). We will present an overview of main results and show that all those approaches are essentially connected. We will also present probabilistic extensions of various other logic systems.",
          "id": "1-25",
          "room": "P19"
        }
      ],
      [
        {
          "lecturer": "Sonia Ramotowska and Fabian Schlotterbeck",
          "title": "Procedural and computational models of semantic and pragmatic processes",
          "group": "Workshop",
          "website": "https://prosandcomps.github.io/",
          "description": "Procedural and computational modeling frameworks have been applied successfully to various aspects of semantic and pragmatic processes, yielding not only a good fit to empirical data but also insights of theoretical relevance. On the one hand, computational (e.g., Bayesian or information theoretic) models rationalize speaker behavior and explain how the listener can use the given information efficiently to infer the intended meaning from an utterance. However, these models often leave the stepwise processing of linguistic information unspecified. On the other hand, procedural procedural (e.g., automata or ACT-R) models explain step-by-step cognitive processes behind meaning-related computations e.g., the process of building sentence representations. However, they often lack the means to combine different information types in an interactive fashion. The goal of this workshop is to bring together researchers applying these two modeling methodologies to discuss their strengths and weaknesses and work towards an integrated approach.",
          "id": "1-26"
        }
      ]
    ]
  }
]

week2 = [
  {
    "time": "9.00am - 10.30am",
    "groups": [
      [
        {
          "lecturer": "Bart Geurts",
          "title": "Common ground",
          "group": "Foundational",
          "description": "Common ground has been a central notion in theoretical pragmatics since the 1970s, and a fixture in theories of presupposition, reference, speech acts, implicature, and many other topics. Given that pragmatics is an interdisciplinary concern, it is hardly surprising that common ground has been discussed across a range of disciplines, including philosophy, linguistics, psychology, and computer science. But for all its importance, there has been relatively little discussion of foundational issues. Stalnaker (2002, 2014) is a notable exception, but he only discusses his own view. There are radically different views on the nature of common ground, i.e. what common ground IS, and there have been no attempts to compare and contrast these views at any length, and consider their implications for the analysis of speech acts and fiction, for example.  In brief, that is the  objective of this course.",
          "id": "2-0",
          "note": "CANCELLED"
        },
        {
          "lecturer": "Niki Pfeifer",
          "title": "Probability logic, language, and cognition",
          "group": "Introductory",
          "description": "Uncertainty is ubiquitous in everyday life communication and reasoning. In this course, we will learn methods and tools to understand language and cognition under uncertainty. We will get interdisciplinary perspectives by combining formal-philosophical and experimental-psychological approaches. In particular, we will understand why coherence-based probability logic offers a unified rationality framework for studying diverse phenomena including conditionals, counterfactuals, connexivity, quantification, reasoning, and argumentation on the normative level. Moreover, on the descriptive level, we will become familiar with recent experimental-psychological results on linguistic phenomena, cognition, and reasoning under uncertainty. Specifically, we will learn about formal and experimental work on nonmonotonic reasoning, conditionals, counterfactuals, quantification, connexivity, and argumentation. Finally, we will achieve a deeper understanding of what it means to be rational under incomplete knowledge and uncertainty.",
          "id": "2-1",
          "room": "P01"
        }
      ],
      [
        {
          "lecturer": "Bruno Guillaume and Kim Gerdes",
          "title": "Treebanking: methodology, tools and applications",
          "group": "Introductory",
          "description": "This introductory course will present a general introduction to dependency-based syntactic treebanks and to two existing frameworks: Universal Dependencies (UD) and its variant Surface Syntactic Universal Dependencies (SUD). After the general introduction of the topic, we will describe a set of tools that are available to help the development of new treebanks (Grew-match and Arborator-grew), with a focus on under-resourced languages. We present some experiments applying these tools to the construction of new treebanks of Spoken French, Zaar, and Beja. Finally, we will illustrate a few applications which are currently developed in the Autogramm project. One application is the automatic extraction of grammatical observations  from treebanks to help linguists in the study of the grammar of new languages (with an example of Wolof). A second application, the use of these annotated treebanks in quantitative typology will be presented.",
          "id": "2-2"
        },
        {
          "lecturer": "Ryan Cotterell",
          "title": "Formal Language Theory and Neural Networks",
          "group": "Advanced",
          "description": "This tutorial is a comprehensive introduction to neural networks, focusing on recurrent neural networks (RNNs) and transformers, and their relationship to formal language theory. We teach how tools from weighted formal language theory can be useful for understanding the inner workings of and predicting the generalization of modern neural architectures. Over the course of five days, we will explore the theoretical properties of RNNs and their representational capacity in relation to different levels of the weighted Chomsky hierarchy, starting with finite-state automata and the special case of bounded-depth hierarchical languages, and then move on to more complex formalisms such as context-free languages and Turing machines. We will prove multiple theoretical properties of RNNs, including the fact that simple RNNs with infinite precision arithmetic and unbounded computation time can emulate a Turing machine and show how RNNs can optimally represent finite-state automata. Finally, we will discuss recent results in the study of Transformer-based language models from the perspective of formal language theory. Finally, we will discuss the implications of these results for the analysis and practical deployment of language models.",
          "id": "2-10",
          "room": "P22"
        }
      ],
      [
        {
          "lecturer": "Rustam Galimullin and Louwe B. Kuijer",
          "title": "Quantification in Dynamic Epistemic Logic",
          "group": "Introductory",
          "description": "Dynamic epistemic logics (DELs) allow one to reason about how knowledge of agents evolves as a result of various information-changing events. Some of the notable examples of DELs include public announcement logic, arrow update logic, and action model logic. Adding quantification over epistemic events in those DELs shifts the perspective from the effects of a particular event to the question of (non-)existence of an event leading to some epistemic outcome. For example, we may want to verify that there is a communication between Alice and Bob such that they both learn some secret, while eavesdropper Eve remains unaware of the secret. In the course, we will present some of the more well-known DELs with quantification and provide highlights of the proofs behind significant technical results. Moreover, we will also discuss some of the tantalising open question spanning the landscape of logics with quantification over information change.",
          "id": "2-4",
          "website": "https://rgalimullin.gitlab.io/esslli23.html",
          "course-material": [
            {"title": "Course website", "link": "https://rgalimullin.gitlab.io/esslli23.html"}
          ],
        },
        {
          "lecturer": "Beniamino Accattoli",
          "title": "Time and Space for the lambda Calculus",
          "group": "Advanced",
          "description": "The lambda calculus is the core model behind functional programs and proof assistants, as well as a formalism for representing the proofs of intuitionistic logic.  Finding reasonable time and space complexity measures for the lambda calculus, that is, measures that are equivalent to those of Turing machines, have been two long-standing problems, solved only in 2014 (for time) and 2022 (for space).  The course aims at explaining three aspects of this topic: 1) The difficulties behind these problems; 2) The tools to solve them, which are based on an abstract theory of implementations of the lambda calculus; 3) How the time and space cost of terms can be captured via type systems for lambda-terms, namely via multi types, a variant of standard type systems for the lambda-calculus.",
          "id": "2-5"
        }
      ],
      [
        {
          "lecturer": "Valentin Goranko and Dmitry Shkatov",
          "title": "First-order Modal and Temporal Logics: state of the art and perspectives",
          "group": "Workshop",
          "website": "https://dshkatov.github.io/fomtl2023/",
          "description": "First-order modal and temporal logics are of fundamental importance for reasoning about necessity, possibility, and temporality. They offer a broad range of actual and potential applications to philosophy, artificial intelligence, computer science, cognitive science, and linguistics.\nThe workshop is intended to bring together researchers and graduate students in the field of first-order modal and temporal logics, to present the state of the art in the field and to discuss the most important directions for future work in the area.",
          "id": "2-6",
          "room": "P20"
        }
      ]
    ]
  },
  {
    "time": "10.30am - 11.00am",
    "groups": [],
    "title": "coffee break"
  },
  {
    "time": "11.00am - 12.30pm",
    "groups": [
      [
        {
          "lecturer": "Elin McCready and Grégoire Winterstein",
          "title": "Communitarian Semantics",
          "group": "Introductory",
          "description": "In the past 15 years, the study of linguistic expressions with meanings keyed to social domains has taken off in linguistics and philosophy. Empirical domains include slurs, gendered expressions, honorifics, discourse markers, and sociolinguistic indexicals, among others; phenomena include epistemic injustice, standpoints, argumentation, and dogwhistling, among others. The aim of this course is twofold: first, to introduce recent developments in this area to students together with the technical tools, both formal and computational, that have been used to analyze them, and, second, to give a birds-eye view of the study of meaning that situates work in this area in the broader semantic landscape.",
          "id": "2-7"
        },
        {
          "lecturer": "Luka Crnic and Yosef Grodzinsky",
          "title": "Monotonicity: Grammar, Processing, and Neural Reflections",
          "group": "Advanced",
          "description": "​​One of the main discoveries of linguistic theory has been that grammar is sensitive to the monotonicity properties of the objects it generates. A related discovery in experimental (neuro)linguistics has been that the monotonicity properties of linguistic objects also affect their processing, and appear to be neuroanatomically localized. We plan to focus on polarity items and quantification more generally. On the empirical side, we will examine how monotonicity impacts grammatical operations, their processing, and their neural reflexes. On the methodological side, we will consider how theoretical and experimental methods can and should be jointly employed to address these questions.",
          "id": "2-8"
        }
      ],
      [
        {
          "lecturer": "John P. McCrae",
          "title": "Introduction to Linguistic Data Science",
          "group": "Introductory",
          "description": "Big data is fundamentally changing the way that linguists can investigate linguistic facts leading to a new research area which combines data science with linguistics. This course provides an introduction to the new area of linguistic data science by means of an introductory course with hands-on data analysis that is focused on key questions in linguistics. This course will first provide a basic introduction to data science and in particular how this can be applied to large corpora using natural language processing techniques. We will then show how this can be used to find answers to problems in syntax, semantics, multilinguality and other areas of linguistics, along with a summary giving perspectives on how these methods can be applied to students' own research.",
          "id": "2-9",
          "room": "P01"
        },
        {
          "lecturer": "Lidia Pivovarova and Andrey Kutuzov",
          "title": "Computational approaches to semantic change detection",
          "group": "Advanced",
          "description": "During the last three years, automatic detection of language change has been intensified by the introduction of several datasets manually annotated for this task, and by a series of shared tasks. However, a gap still exists between theoretic understanding of various linguistic phenomena contributing to language change and abilities of computational methods to capture these phenomena. The goal of this course is to provide a broad overview of this novel research area and discuss in detail various methods used to detect word meaning shift. We will also discuss open problems and possible practical applications. Every day of the course will feature a lecture and a small practice session. The course will allow students to start working in this research area.",
          "id": "2-3",
          "course-material": [
            {"title": "Course GitHub", "link": "https://github.com/lmphcs/semshift_esslli2023"}
          ],
        }
      ],
      [
        {
          "lecturer": "Matteo Acclavio and Paolo Pistone",
          "title": "An Introduction to Proof Equivalence",
          "group": "Introductory",
          "description": "The goal of this course is to provide an overview on important results and current research trends in proof theory around the notion of proof equivalence. This is the problem of understanding when two formal derivations represent ``the same'' proof, both intuitively and in more precise semantical terms. The search for more canonical representations of logical arguments has lead to the design of new proof systems based on ideas from graph theory or category theory.  Research on proof equivalence has received considerable attention in the proof-theory community, and has led in recent years to several applications in computer science (e.g. for program equivalence or proof-search). However, a structured presentation of fundamental results and perspectives in this area is still missing, and we consider this course as a first step in the direction of filling this gap.",
          "id": "2-11",
          "room": "P22"
        },
        {
          "lecturer": "Balder ten Cate and Carsten Lutz",
          "title": "Logic, Data Examples, and Learning",
          "group": "Introductory",
          "description": "In logic, data examples are useful when a logical formula must be  synthesized or communicated. This includes tasks such as  the reverse engineering of logical queries, debugging and refinement  of formal specifications, as well as various forms of learning.\nThis course provides a uniform introduction to the use of data examples in logic, covering logical formalisms that range from propositional logic  to first-order logic (including conjunctive queries and description logics), and addressing the following questions:\n* When, and to what extent, can a logical formula be described by a    small number of data examples. (\"From Formulas to Data Examples\")\n* How to construct a fitting formula from a set of data examples?    When more than one fitting formula exists, which one should be    preferred?  (\"From Data Examples to Formulas\")\n* When is a fitting formula likely to generalize from input examples to     unseen data examples, and how many input examples are     required to achieve this? (\"PAC Learning\")\n* In interactive design and refinement systems, data examples provide     a means of communication between the system and the user. This    can be modeled as an interactive learning setting with a learner and    an oracle. When is efficient interactive learning of this type possible?",
          "id": "2-12",
          "room": "PB"
        }
      ],
      [
        {
          "lecturer": "Michael Moortgat and Mehrnoosh Sadrzadeh",
          "title": "Modalities in substructural logics: Applications at the interfaces of logic, language and computation (Monday and Tuesday only)",
          "group": "Workshop",
          "website": "https://sites.google.com/view/esslli2023course/workshop",
          "description": "By calling into question the implicit structural rules that are taken for granted in classical logic, substructural logics have brought to the fore new forms of reasoning with applications in many interdisciplinary areas of interest. Modalities, in the substructural setting, provide the tools to control and finetune the logical resource management. The workshop explores the uses of substructural modalities in areas where logic meets linguistics and computer science. The workshop is supported by the EU-funded MOSAIC project (Modalities in Substructural Logics: Theory, Methods and Applications). A complementary proposed course is \"Modal Lambek Calculus and its Natural Language Applications\".\n<b>Resources:</b><ul style=\"margin-left: 2em;\"><li><a href=\"https://sites.google.com/view/esslli2023course/workshop\" target=\"_blank\">Workshop website</a></li><li><a href=\"https://easychair.org/cfp/AMSLO23\" target=\"_blank\">EasyChair</a></li></ul>",
          "id": "2-13"
        }
      ]
    ]
  },
  {
    "time": "12.30pm - 2.00pm",
    "groups": [],
    "title": "lunch"
  },
  {
    "time": "2.00pm - 3.30pm",
    "groups": [
      [
        {
          "lecturer": "Annemarie van Dooren and Anouk Dieuleveut",
          "title": "Decomposing the meaning of modals",
          "group": "Foundational",
          "description": "Modal statements, like “The keys must be in the drawer” or “We must take the train”, involve a complex interplay of syntax, semantics, and pragmatics. The goal of this introductory class is to understand how we can decompose the meaning of modal words like can or must, by going through their standard quantificational analysis inherited from modal logic, with particular attention to the work of Kratzer. The class will combine insights from various disciplines: logic, philosophy and formal semantic theories of modality, cross-linguistic fieldwork, psycholinguistics experiments, and language acquisition.",
          "id": "2-14"
        },
        {
          "lecturer": "Cornelia Ebert and Markus Steinbach",
          "title": "The semantics of visual communication. Theoretical approaches to visual meaning aspects in co-speech gestures and sign language",
          "group": "Advanced",
          "description": "In recent formal semantic research, both sign language and co-speech gestures have been analyzed by applying the theories established for spoken languages to visual meaning aspects. Only little attention has been paid to modelling the specific properties of the visual transmission channel. However, it is now becoming evident that the formal linguistic repertoire needs to be extended to meet the modality-specific requirements of visual communication such as the higher degree of iconicity of gestures and signs, the systematic use of the body of the speaker or signer and the space in front of the body to express, for instance, logical variables, comparative constructions, tense, topographic relations or context shift and the option to demonstrate actions and events. In this class, we will discuss selected examples illustrating the expressive power of visible communication and discuss recent formal accounts that enhance the formal linguistic apparatus to develop formally precise theories that can deal with and model the semantics of visual and multimodal communication.",
          "id": "2-15"
        }
      ],
      [
        {
          "lecturer": "Timothée Bernard and Pascal Amsili",
          "title": "Natural language syntax: parsing and complexity",
          "group": "Foundational",
          "description": "This course aims to provide an introduction to the fields of formal grammars and syntactic parsing, with a focus on their application to natural language. We introduce the concepts of formal language, formal grammar and automaton, and the notion of complexity reflected by the Chomsky-Schützenberger hierarchy. We present how natural language and popular syntactic formalisms fit into this picture. We review at length the evolution of parsing algorithms for natural language, from the classic chart-based paradigm to contemporary shift-reduce parsers, graph-based algorithms, and CCG parsing. We discuss the impact on the field of the advances in machine-learning and introduce some of the key aspects of neural-based parsers and in particular the use of the vector representations of linguistic units produced by language models.",
          "id": "2-16"
        },
        {
          "lecturer": "Martha Palmer and James Pustejovsky",
          "title": "A Uniform Meaning Representation for NLP Systems",
          "group": "Advanced",
          "description": "Impressive progress has been made in many aspects of natural language processing (NLP) in recent years. Most notably, the achievements of transformer-based large language models such as ChatGPT would seem to obviate the need for any type of semantic representation beyond what can be encoded as contextualized word embeddings of surface text. Advances have been particularly notable in areas where large training data sets exist and it is advantageous to build an end-to-end training architecture without resorting to intermediate representations. For any truly interactive NLP applications, however, a more complete understanding of the information conveyed by each sentence is needed to advance the state of the art. Here \"understanding'' entails the use of some form of meaning representation. NLP techniques that can accurately capture the required elements of the meaning of each utterance in a formal representation are critical to making progress in these areas and have long been a central goal of the field.\nAs with end-to-end NLP applications, the dominant approach for deriving meaning representations from raw textual data is through the use of machine learning and appropriate training data. This allows the development of systems that can assign appropriate meaning representations to previously unseen sentences. Generating training data that represents meaning, however, is a very different undertaking from collecting human translated text or transcribed speech as it is not ``naturally occurring.'' It requires the development of a consensus on formal meaning representations that can be used by humans to annotate significant amounts of data for the sole purpose of training the machine learning algorithms.  This has been an elusive target because it is a delicate balancing act between a number of factors. It must provide fair and equal treatment for multiple languages, be intuitive enough to enable fast, consistent human annotation, and support the training of accurate, useful automatic modules that work well in downstream applications.  A meaning representation that strikes the right balance would solve one of the long-standing intellectual problems in the field and  have a transformative effect on NLP specifically, and on Artificial Intelligence in general.\nIn this course, we describe the framework of Uniform Meaning Representations (UMRs), a recent cross-lingual, multi-sentence incarnation of Abstract Meaning Representations (AMRs), that addresses these issues and comprises such a transformative representation. Incorporating Named Entity tagging, discourse relations, intra-sentential coreference, a partial treatment of negation and modality, and the popular PropBank-style predicate argument structures with semantic role labels, into a single directed acyclic graph structure,  UMR builds on AMR and keeps the essential characteristics of AMR while making it cross-lingual and extending it to a document-level representation.\nWe introduce the basic structural representation of UMR and describe its application to multiple languages. We present a formal semantic interpretation of UMR incorporating a continuation-based semantics for scope phenomena involving modality, negation, and quantification. We describe how UMR encodes TAM (Tense Aspect Modality) information in multiple languages. We describe parsing algorithms that generate AMR and UMR representations over multiple languages. Finally, we introduce an extension to UMR for encoding gesture in multimodal dialogue, Gesture AMR (GAMR), which aligns with speech-based UMR to account for situated grounding in dialogue.",
          "id": "2-17",
          "room": "P01"
        }
      ],
      [
        {
          "lecturer": "Giulio Guerrieri",
          "title": "The lambda-calculus: from simple types to non-idempotent intersection types",
          "group": "Introductory",
          "description": "The (pure, untyped) lambda-calculus is a Turing-complete model of computation, simply based on function abstraction and application using variable binding and substitution. Thanks to thesimplicity of the formal system, it is well suited for theoretical investigations in mathematical logic, categorical theory, computability and even complexity. On the other hand, the lambda-calculus is at the core of many functional programming languages (such as LISP, Haskell, OCaml) and proof-assistants (such as Coq and Agda).\nThere are many variants of the lambda-calculus where functions can be applied only if they are capable of accepting the given input's \"type\" of data. Typed lambda-calculi are weaker than the untyped lambda calculus, in the sense that the former can express less than the latter can, but on the other hand typed lambda-calculi can only represent \"well-behaved\" programs, in that \"well-typed programs cannot go wrong\" (R. Milner).\nIn this course we investigate two typed versions of the lambda-calculus. The first one is the simply typed lambda-calculus, which is the computational counterpart--via Curry-Howard correspondence--of natural deduction for intuitionistic propositional logic. We will show that there every evaluation strategy terminates (strong normalization) for every simply typed lambda-term, but the type system is too restrictive because there are \"well-behaved\" programs that cannot be represented there.\nThe second typed variant of the lambda-calculus we will study is the one endowed with a non-idempotent intersection type system. Such a type system increase the typability power of simple types by introducing a new intersection type constructor ∧, which commutative, associative and non-idempotent (A ∧ A is not equivalent to A). The intuition is that term of type A ∧ A ∧ B can be seen as a resource that, during execution, can be used once as a data of type B and twice as a data of type A. Non-idempotent intersection types constitute a powerful tool to reason about qualitative semantic properties of programs: we will show that they characterize different notions of termination in the lambda-calculus, for different notions of evaluation. In this respect, non-idempotent intersection types are able to capture all and only the \"well-behaved\" programs, if we assume that a \"good behavior\" is the fact that evaluation terminates. Moreover, they not only provide qualitative characterization of operational properties, but also quantitative ones, in the sense that any type derivation of a term gives a bound to the execution time for that term (the number of steps to reach a normal form).",
          "id": "2-18",
          "room": "P22",
          "website": "https://pageperso.lis-lab.fr/~giulio.guerrieri/ESSLLI2023.html",
          "course-material": [
            {"title": "Course website", "link": "https://pageperso.lis-lab.fr/~giulio.guerrieri/ESSLLI2023.html"}
          ]
        },
        {
          "lecturer": "Anupam Das",
          "title": "Proof theory of arithmetic",
          "group": "Advanced",
          "description": "This course will introduce students to the fundamentals of the proof theory of arithmetic. We shall assume some previous familiarity with basic proof theory, but will go further to show how to apply these techniques in order to obtain metalogical results of profound importance at the interface between logic and computation. Namely, we shall present a seminal consistency proof of PA via (ordinal-assigned) infinitary cut-elimination, and following on from that derive the famous classification of PA's provably total recursive functions by ordinal recursion. The course will conclude by surveying other consistency proofs and classifications of PA's provably total recursive functions, namely via Goedel's T, a higher-typed of primitive recursion, as well as the adaptation of these results to important fragments and extensions of PA.",
          "id": "2-19",
          "website": "https://www.anupamdas.com/esslli23/"
        }
      ],
      [
        {
          "lecturer": "Michael Moortgat and Mehrnoosh Sadrzadeh",
          "title": "Modalities in substructural logics: Applications at the interfaces of logic, language and computation (Monday and Tuesday only)",
          "group": "Workshop",
          "website": "https://sites.google.com/view/esslli2023course/workshop",
          "id": "2-13"
        }
      ]
    ]
  },
  {
    "time": "3.30pm - 3.50pm",
    "groups": [],
    "title": "coffee break"
  },
  {
    "time": "3.50pm - 4.50pm",
    "groups": [],
    "title": "Student Session (StuS)<br/>Room: PA",
    "link": "courses-workshops-accepted/student-session-call.html"
  },
  {
    "time": "5.00pm - 6.30pm",
    "groups": [
      [
        {
          "lecturer": "Zhaohui Luo",
          "title": "Advanced Topics in Formal Semantics Based on Modern Type Theories",
          "group": "Advanced",
          "description": "Formal semantics based on modern type theories (MTT-semantics) provides us with not only a viable alternative to Montague’s semantics, but potentially an attractive full-blown semantic tool with advantages in many respects. However, the salient features of MTT-semantics may only be discussed properly when more advanced semantic topics are considered. For example, people may ask: how does it fare with semantic issues such as events and anaphoric reference, and could it offer a good treatment of intriguing linguistic features such as copredication? In the past, some of these advanced issues have only been dealt with briefly [1], but more recently they have been studied more in depth in the proposer’s monograph [2]. In this course, after an overview introduction, I shall consider the following topics in MTT-semantics: event semantics, anaphoric references, copredication and dependent categorial grammars. I’ll also compare the treatments with those studied in the Montagovian approach and discuss their respective merits.\n[1] S. Chatzikyriakidis and Z. Luo. Formal Semantics in Modern Type Theories. Wiley/ISTE, 2020. \n[2] Z. Luo. Modern Type Theories: Their Development and Applications. Tsinghua University Press, 2022. In press.",
          "id": "2-20",
          "course-material": [
            {"title": "Course proposal", "link": "https://2023.esslli.eu/images/2023/documents/Formal-Semantics/ESSLLI23proposal.pdf"},
            {"title": "Slides for Lecture I", "link": "https://2023.esslli.eu/images/2023/documents/Formal-Semantics/ESSLLI23slidesL1.pdf"},
            {"title": "Slides for all 5 lectures", "link": "https://www.cs.rhul.ac.uk/home/zhaohui/lecture-notes.html"},
            {"title": "Papers/books on MTT-semantics", "link": "https://www.cs.rhul.ac.uk/home/zhaohui/lexsem.html"}
          ]
        },
        {
          "lecturer": "Patrick Elliott and Lisa Hofmann",
          "title": "Explaining anaphoric accessibility: navigating non-veridical environments in dynamic semantics",
          "group": "Advanced",
          "description": "Classical dynamic accounts of anaphora rely on logical operators arbitrarily manipulating anaphoric information. Alongside conceptual concerns of explanatory (in)adequacy, classical accounts are known to make poor empirical predictions for non-veridical environments (see, e.g., Roberts 1987, Krahmer and Muskens 1995). In this course, we motivate an alternative approach, which treats logical operators as fundamentally truth-functional. In the first half of the course, we explore an approach to anaphora based on the Strong Kleene account of presupposition projection. The initial goal will be to derive and improve upon Groenendijk & Stokhof's (1991) accessibility generalizations, with a particular focus on negation and disjunction. The latter half of the course zooms in on counterfactual content: The initial Strong Kleene account fails to capture key constraints on the (anti)veridicality of anaphorically active content. We revise the account by intensionalizing discourse referents, which are in turn interpreted relative to both a local and a global intensional context.",
          "id": "2-21"
        }
      ],
      [
        {
          "lecturer": "Tim Van de Cruys",
          "title": "Computational Creativity",
          "group": "Introductory",
          "description": "This course provides an introduction to the field of computational creativity. We will examine different approaches to the computational modeling of creativity, and see how they relate to theories of human creativity. The course focuses primarily on computational creativity from a language-oriented perspective. As such, we will examine different applications of creative language generation (such as metaphor, humor, neologisms, poetry, and stories) from a computational perspective. Additionally, cross-modal and multi-modal approaches to computational creativity will be explored. Along the way, we will discuss a number of crucial topics, such as the preconditions of computational creativity, the evaluation of computationally creative systems, and the ethical implications.",
          "id": "2-22",
          "room": "P22"
        },
        {
          "lecturer": "Fausto Carcassi and Michael Franke",
          "title": "The probabilistic Language of Thought",
          "group": "Advanced",
          "description": "Computational modeling of cognition is at the heart of cognitive science. However, our most developed and expensive models, artificial neural networks, struggle to match some striking human skills: few- or zero-shot learning (figuring out a rule from few examples) and manipulating compositionally structured representations and symbols with a rich logical structure. This course focuses on a promising framework to model these human cognitive skills: the probabilistic Language of Thought (LoT). We will start with the philosophical underpinnings of the program in the work of Jerry Fodor. Then, we will discuss recent developments, combining the LoT with probabilistic approaches to learning to develop models of category acquisition across a variety of conceptual domains. This will require a discussion of several technical tools (formal grammars, compositional semantics, Bayesian inference). Finally, we will look at recent promising developments in the field (neurosymbolic learning, the child as a hacker).",
          "id": "2-23"
        }
      ],
      [
        {
          "lecturer": "Louwe B. Kuijer",
          "title": "Conditional logics of preference: how to make the best choice",
          "group": "Introductory",
          "description": "This course is about preference structures. These are versatile models, consisting of a set of alternatives and a relation, denoted <, between them that indicates \"betterness\" or \"preference\" of some kind. The versatility comes from the fact that preferences, and the alternatives that they rank, can mean many things in different contexts.\nThe most straightforward meaning is if < represents a utility comparison of an agent, e.g., \"coffee < tea\". But < could also represent a plausibility ordering (more plausible is \"better\"), a defeat relation among strategies (\"scissors < rock\"), et cetera. By studying preference structure we can improve our understanding of all these different interpretations of <.\nWe will study these structures through the vehicle of conditional logics. These logics have an operator B(p|q), with the meaning that \"if q holds, then p is the best choice\". In particular, we will investigate how B(p|q) depends on assumptions about <.",
          "id": "2-24"
        },
        {
          "lecturer": "Fan Yang",
          "title": "Logics of dependence and independence",
          "group": "Advanced",
          "description": "This course provides a concise introduction to logics of dependence and independence (DIL), which are  formalisms for reasoning about dependence and independence relations in sciences. We will study the novel semantics of DIL -- team semantics. The basic idea of team semantics is that dependency properties can only manifest themselves in multitudes, and thus formulas of DIL are evaluated on sets of assignments (called teams) instead of single assignments as in the usual Tarskian semantics. A team can be naturally viewed as a database, a dataset, an information state, etc. Thanks to the simple structure of teams and the abundance of their interpretations in various fields of science, DIL have found a number of applications in addressing issues in database theory, social choice, quantum theory, formal linguistics, and so on. This course will also discuss recent developments on these applications.",
          "id": "2-25",
          "course-material": [
            {"title": "Course website", "link": "https://sites.google.com/view/dil-esslli23/"}
          ],
          "website": "https://sites.google.com/view/dil-esslli23/"
        }
      ]
    ]
  }
]
